{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **First Approach**: Hyperparameter Tuning for Decision Tree Regressor\n"," \n","Since Decision Tree Regressor is the best performer compared to the other models regarding the cross-validation method, we choose Decision Tree Regressor in this case for hyperparameter tuning. We use the Grid Search method to search for the best hyperparameter and then use the hyperparameters we got from the search and apply them to the model. After, we will compare the result of the before and after-tuned hyperparameter models. From our development, we see that the model after the hyperparameter is tuned gives better results regarding the RMSE score from both hold-out and cross-validation evaluation.  "]},{"cell_type":"markdown","metadata":{},"source":["### Train-Test Split (80-20) -- Regularization"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[],"source":["%store -r X_train\n","%store -r X_test\n","%store -r y_train\n","%store -r y_test\n","%store -r ind_vars\n","%store -r dep_var\n","%store -r X\n","%store -r y\n","%store -r df\n","\n","def rmse(a,b):\n","    return np.sqrt(np.mean((a-b)**2))"]},{"cell_type":"markdown","metadata":{},"source":["### Linear Regression"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE:7064.543640307604\n","Mean Squared Error:49907776.84581061\n","R2:0.9589910139299496\n"]}],"source":["import numpy as np\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score\n","\n","# Linear Regression model RMSE, MSE, R2 results\n","from sklearn.linear_model import LinearRegression\n","\n","reg = LinearRegression()\n","reg.fit(X_train, y_train)\n","# results based on test data\n","y_pred = reg.predict(X_test)\n","print(\"RMSE:\" + str(rmse(y_test, y_pred)))\n","print(\"Mean Squared Error:\" + str(mean_squared_error(y_test, y_pred)))\n","print(\"R2:\" + str(r2_score(y_test, y_pred)))"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE:7138.763721747759\n","Mean Squared Error:50961947.47494191\n","R2:0.9589129226026707\n"]}],"source":["# Linear regression results based on train data\n","y_train_pred = reg.predict(X_train)\n","print(\"RMSE:\" + str(rmse(y_train, y_train_pred)))\n","print(\"Mean Squared Error:\" + str(mean_squared_error(y_train, y_train_pred)))\n","print(\"R2:\" + str(r2_score(y_train, y_train_pred)))"]},{"cell_type":"markdown","metadata":{},"source":["### Elastic Net"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE:36280.82875065643\n","Mean Squared Error:683482291.6436001\n","R2:0.4383858078124082\n"]}],"source":["# Elastic Net model RMSE, MSE, R2 results\n","from sklearn.linear_model import ElasticNet\n","\n","enr = ElasticNet()\n","enr.fit(X_train, y_train)\n","y_pred = enr.predict(X_test)\n","print(\"RMSE:\" + str(rmse(y_test, y_pred)))\n","print(\"Mean Squared Error:\" + str(mean_squared_error(y_test, y_pred)))\n","print(\"R2:\" + str(r2_score(y_test, y_pred)))"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE:36601.404051881764\n","Mean Squared Error:698959805.1265999\n","R2:0.4364772730677209\n"]}],"source":["# Elastic Net results based on train data\n","y_train_pred = enr.predict(X_train)\n","print(\"RMSE:\" + str(rmse(y_train, y_train_pred)))\n","print(\"Mean Squared Error:\" + str(mean_squared_error(y_train, y_train_pred)))\n","print(\"R2:\" + str(r2_score(y_train, y_train_pred)))"]},{"cell_type":"markdown","metadata":{},"source":["### Lasso Regression"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE:48942.192804157065\n","Mean Squared Error:51343015.62755987\n","R2:0.9578116849570364\n"]}],"source":["# Lasso Regression model and RMSE, MSE results\n","from sklearn.linear_model import Lasso\n","\n","lasso_reg = Lasso(alpha=10)\n","lasso_reg.fit(X_train, y_train)\n","y_pred = lasso_reg.predict(X_test)\n","print(\"RMSE:\" + str(rmse(y_test, y_pred)))\n","print(\"Mean Squared Error:\" + str(mean_squared_error(y_test, y_pred)))\n","print(\"R2:\" + str(r2_score(y_test, y_pred)))"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE:49177.35139422539\n","Mean Squared Error:52157080.74892002\n","R2:0.957949369682088\n"]}],"source":["# Lasso regression results based on train data\n","y_train_pred = lasso_reg.predict(X_train)\n","print(\"RMSE:\" + str(rmse(y_train, y_train_pred)))\n","print(\"Mean Squared Error:\" + str(mean_squared_error(y_train, y_train_pred)))\n","print(\"R2:\" + str(r2_score(y_train, y_train_pred)))"]},{"cell_type":"markdown","metadata":{},"source":["### SGD Regressor"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Konto\\anaconda3\\envs\\dsenv\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"name":"stdout","output_type":"stream","text":["RMSE:48877.96264522262\n","Mean Squared Error:53425358.15038619\n","R2:0.9561006338762502\n"]}],"source":["# SGD Regressor odel and RMSE, MSE, R2 results\n","from sklearn.linear_model import SGDRegressor\n","\n","clf = SGDRegressor(tol=1e-3)\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","print(\"RMSE:\" + str(rmse(y_test, y_pred)))\n","print(\"Mean Squared Error:\" + str(mean_squared_error(y_test, y_pred)))\n","print(\"R2:\" + str(r2_score(y_test, y_pred)))"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE:49132.43274222368\n","Mean Squared Error:53641245.3561951\n","R2:0.9567527908794535\n"]}],"source":["# SGD regression results based on train data\n","y_train_pred = clf.predict(X_train)\n","print(\"RMSE:\" + str(rmse(y_train, y_train_pred)))\n","print(\"Mean Squared Error:\" + str(mean_squared_error(y_train, y_train_pred)))\n","print(\"R2:\" + str(r2_score(y_train, y_train_pred)))"]},{"cell_type":"markdown","metadata":{},"source":["### Decision Tree Regressor (MAIN)"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE:48942.192804157065\n","Mean Squared Error:51343015.62755987\n","R2:0.9578116849570364\n"]}],"source":["# Decision Tree Regressor and RMSE, MSE results -- best performing model for approach 1\n","from sklearn.tree import DecisionTreeRegressor\n","\n","dtr = DecisionTreeRegressor()\n","dtr.fit(X_train, y_train)\n","y_pred = lasso_reg.predict(X_test)\n","print(\"RMSE:\" + str(rmse(y_test, y_pred)))\n","print(\"Mean Squared Error:\" + str(mean_squared_error(y_test, y_pred)))\n","print(\"R2:\" + str(r2_score(y_test, y_pred)))"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["total_cases 0.8852308890127735\n","new_cases 1.615812674482884e-05\n","new_deaths 5.278637024552044e-05\n","reproduction_rate 0.00013344676438886764\n","icu_patients 0.0005119393975910734\n","hosp_patients 9.051440625790422e-05\n","total_tests 0.06347292660572788\n","new_tests 2.4709047397695195e-06\n","positive_rate 0.000566975741229598\n","tests_per_case 3.97810346005335e-05\n","total_vaccinations 0.0009000164699290095\n","people_vaccinated 0.0005731635142816444\n","people_fully_vaccinated 0.002658120166017643\n","new_vaccinations 1.962398320831818e-05\n","new_people_vaccinated_smoothed 7.221796350239494e-05\n","stringency_index 0.00026135882532468327\n","population 0.026850387713382773\n","population_density 0.0007004146251540388\n","median_age 0.002294680295881222\n","aged_65_older 0.0031888693036596777\n","aged_70_older 1.0664248362189202e-09\n","gdp_per_capita 9.459792648870627e-05\n","extreme_poverty 0.00026535344547931513\n","cardiovasc_death_rate 5.895212799198614e-05\n","diabetes_prevalence 1.1479663292782217e-05\n","female_smokers 0.0016591751617159901\n","male_smokers 0.005251844839072477\n","hospital_beds_per_thousand 0.0032967259419595498\n","life_expectancy 0.0008440113968583399\n","human_development_index 0.000881117206075368\n"]}],"source":["# get importance\n","importance = dtr.feature_importances_\n","# summarize feature importance\n","for a,b in zip(ind_vars, importance):\n","\tprint(a, b)"]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE:49806.42621478479\n","Mean Squared Error:0.0\n","R2:1.0\n"]}],"source":["# Decision Tree regression results based on train data\n","y_train_pred = dtr.predict(X_train)\n","print(\"RMSE:\" + str(rmse(y_train, y_train_pred)))\n","print(\"Mean Squared Error:\" + str(mean_squared_error(y_train, y_train_pred)))\n","print(\"R2:\" + str(r2_score(y_train, y_train_pred)))"]},{"cell_type":"markdown","metadata":{},"source":["### Random Forest Regressor"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Konto\\AppData\\Local\\Temp\\ipykernel_17280\\1045160469.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  rfr.fit(X_train, y_train)\n"]},{"name":"stdout","output_type":"stream","text":["RMSE:49044.786532821665\n","Mean Squared Error:17321686.87345887\n","R2:0.985766851168345\n"]}],"source":["# Random Forest and RMSE, MSE, R2 results\n","from sklearn.ensemble import RandomForestRegressor\n","\n","rfr = RandomForestRegressor(n_estimators=50, max_leaf_nodes=16, n_jobs=-1)\n","rfr.fit(X_train, y_train)\n","y_pred = rfr.predict(X_test)\n","print(\"RMSE:\" + str(rmse(y_test, y_pred)))\n","print(\"Mean Squared Error:\" + str(mean_squared_error(y_test, y_pred)))\n","print(\"R2:\" + str(r2_score(y_test, y_pred)))"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE:49526.52632128954\n","Mean Squared Error:15133220.23018828\n","R2:0.9877991359891749\n"]}],"source":["# Random Forest regression results based on train data\n","y_train_pred = rfr.predict(X_train)\n","print(\"RMSE:\" + str(rmse(y_train, y_train_pred)))\n","print(\"Mean Squared Error:\" + str(mean_squared_error(y_train, y_train_pred)))\n","print(\"R2:\" + str(r2_score(y_train, y_train_pred)))"]},{"cell_type":"markdown","metadata":{},"source":["### Cross validation\n","We apply cross-validation with k=5 folds to estimate the performance of the machine learning model on unseen data (non-training data). The Decision Tree Regressor is the best performer in terms of MSE while linear regression is the worst performer in terms of the RMSE score."]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import cross_val_score\n","\n","# result for Linear Regression with cross valisation and RMSE scores, mean, standard deviation\n","def display_scores(scores):\n","    print(\"Scores:\", np.sqrt(-scores))\n","    print(\"Mean:\", np.sqrt(-scores).mean())\n","    print(\"Standard deviation:\", np.sqrt(-scores).std())"]},{"cell_type":"markdown","metadata":{},"source":["### Linear Regression"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Scores: [13752.52130363 11688.38733639 12599.55886119 30235.38296593\n"," 13180.05915096]\n","Mean: 16291.181923619486\n","Standard deviation: 7005.403974159406\n"]}],"source":["reg = LinearRegression()\n","#scores = cross_val_score(reg, X, y, np.ravel(y), cv=5,scoring='neg_mean_squared_error')\n","scores = cross_val_score(reg, X, y, cv=5,scoring='neg_mean_squared_error')\n","display_scores(scores)"]},{"cell_type":"markdown","metadata":{},"source":["### Elastic Net"]},{"cell_type":"code","execution_count":114,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Scores: [13964.0081663  30336.13582157 31123.46956271 19256.77729951\n"," 39416.09996319]\n","Mean: 26819.29816265587\n","Standard deviation: 9077.70518201681\n"]}],"source":["# result for ElasticNet with cross validation and RMSE scores, mean, standard deviation\n","enr = ElasticNet()\n","scores = cross_val_score(enr, X, y, cv=5,scoring='neg_mean_squared_error')\n","display_scores(scores)"]},{"cell_type":"markdown","metadata":{},"source":["### Lasso Regression"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Scores: [12936.12603374 10214.45587422 12511.49416854 27743.25905593\n"," 11698.83801519]\n","Mean: 15020.834629521833\n","Standard deviation: 6428.682929017829\n"]}],"source":["# result for Lasso Regression with cross validation and RMSE scores, mean, standard deviation\n","lasso_reg = Lasso(alpha=10)\n","scores = cross_val_score(lasso_reg, X, y, cv=5,scoring='neg_mean_squared_error')\n","display_scores(scores)"]},{"cell_type":"markdown","metadata":{},"source":["### SGD Regressor"]},{"cell_type":"code","execution_count":116,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Konto\\anaconda3\\envs\\dsenv\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","c:\\Users\\Konto\\anaconda3\\envs\\dsenv\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","c:\\Users\\Konto\\anaconda3\\envs\\dsenv\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","c:\\Users\\Konto\\anaconda3\\envs\\dsenv\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","c:\\Users\\Konto\\anaconda3\\envs\\dsenv\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"name":"stdout","output_type":"stream","text":["Scores: [14398.26253677  9822.31224414 12325.323009   28199.47252297\n"," 11847.04529093]\n","Mean: 15318.483120761744\n","Standard deviation: 6602.794503375161\n"]}],"source":["# result for SGD Regressor with cross validation and RMSE score, mean, standard deviation\n","clf = SGDRegressor(max_iter=1000, tol=1e-3)\n","scores = cross_val_score(clf, X, y, cv=5,scoring='neg_mean_squared_error')\n","display_scores(scores)"]},{"cell_type":"markdown","metadata":{},"source":["### Decision Tree Regressor"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Scores: [ 7884.98154711 13555.58359817 12192.43199146  9836.18309743\n"," 17439.53314784]\n","Mean: 12181.742676400083\n","Standard deviation: 3270.9545922277207\n"]}],"source":["# result for Decision Tree Regressor with cross validation and RMSE score, mean, standard deviation\n","dtr = DecisionTreeRegressor()\n","scores = cross_val_score(dtr, X, y, cv=5,scoring='neg_mean_squared_error')\n","display_scores(scores)"]},{"cell_type":"markdown","metadata":{},"source":["### Random Forest Regressor"]},{"cell_type":"code","execution_count":118,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Konto\\anaconda3\\envs\\dsenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  estimator.fit(X_train, y_train, **fit_params)\n","c:\\Users\\Konto\\anaconda3\\envs\\dsenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  estimator.fit(X_train, y_train, **fit_params)\n","c:\\Users\\Konto\\anaconda3\\envs\\dsenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  estimator.fit(X_train, y_train, **fit_params)\n","c:\\Users\\Konto\\anaconda3\\envs\\dsenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  estimator.fit(X_train, y_train, **fit_params)\n","c:\\Users\\Konto\\anaconda3\\envs\\dsenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  estimator.fit(X_train, y_train, **fit_params)\n"]},{"name":"stdout","output_type":"stream","text":["Scores: [ 7138.83474172  9097.52204026 10285.65790418 10416.03989493\n"," 12028.27810299]\n","Mean: 9793.266536816933\n","Standard deviation: 1622.0752864437839\n"]}],"source":["# result for Random Forest Regressor with cross validation and RMSE score, mean, standard deviation\n","rfr = RandomForestRegressor(n_estimators=50, max_leaf_nodes=16, n_jobs=-1)\n","scores = cross_val_score(rfr, X, y, cv=5,scoring='neg_mean_squared_error')\n","display_scores(scores)"]},{"cell_type":"markdown","metadata":{},"source":["We do the hold-out method by splitting the data into train-test sets of 80-20 for all the chosen models above. Then we compare the RMSE, MSE, and R2 of each model. We noted that Linear Regression is the best performer in this case.\n"," \n","However, we apply cross-validation with k=5 folds. The Decision Tree Regressor is the best performer with an average slightest error, while Linear regression worst performer, in relation to the RMSE score.\n"," \n","Additionally, the Linear Regression model seems to be overfitting when we apply the hold-out method of train-test of 80-20. The training performance gives better results than the testing performance.\n"]},{"cell_type":"markdown","metadata":{},"source":["### Hyperparameter Tuning and Validation\n","\n","Since Decision Tree Regressor is the best performer compared to the other models regarding the cross-validation method, we choose Decision Tree Regressor in this case for hyperparameter tuning. We use the Grid Search method to search for the best hyperparameter and then use the hyperparameters we got from the search and apply them to the model. After, we will compare the result of the before and after-tuned hyperparameter models. From our development, we see that the model after the hyperparameter is tuned gives better results regarding the RMSE score from both hold-out and cross-validation evaluation.  "]},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","from datetime import datetime\n","\n","# Hyper parameters range intialization for tuning \n","parameters={\"splitter\":[\"best\",\"random\"],\n","            \"max_depth\" : [1,3,5,7,9,11,12],\n","           \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n","           \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n","           \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n","           \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] }\n","\n","# calculating different regression metrics\n","tuning_model=GridSearchCV(dtr,param_grid=parameters,scoring='neg_mean_squared_error',cv=3,verbose=3)\n","\n","# function for calculating how much time take for hyperparameter tuning\n","def timer(start_time=None):\n","    if not start_time:\n","        start_time=datetime.now()\n","        return start_time\n","    elif start_time:\n","        thour,temp_sec=divmod((datetime.now()-start_time).total_seconds(),3600)\n","        tmin,tsec=divmod(temp_sec,60)\n","        #print(thour,\":\",tmin,':',round(tsec,2))"]},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[],"source":["X=df.iloc[:,:-1]\n","y=df.iloc[:,-1]"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["%%capture\n","\n","start_time=timer(None)\n","\n","tuning_model.fit(X,y)\n","\n","timer(start_time)"]},{"cell_type":"code","execution_count":122,"metadata":{},"outputs":[{"data":{"text/plain":["{'max_depth': 7,\n"," 'max_features': 'auto',\n"," 'max_leaf_nodes': 10,\n"," 'min_samples_leaf': 2,\n"," 'min_weight_fraction_leaf': 0.1,\n"," 'splitter': 'best'}"]},"execution_count":122,"metadata":{},"output_type":"execute_result"}],"source":["# best hyperparameters \n","tuning_model.best_params_"]},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[{"data":{"text/plain":["-0.0003876787787329035"]},"execution_count":123,"metadata":{},"output_type":"execute_result"}],"source":["# best model score\n","tuning_model.best_score_"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[],"source":["tuned_hyper_model= DecisionTreeRegressor(max_depth=5,max_features='auto',max_leaf_nodes=50,min_samples_leaf=2,min_weight_fraction_leaf=0.1,splitter='random')"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[{"data":{"text/plain":["DecisionTreeRegressor(max_depth=5, max_features='auto', max_leaf_nodes=50,\n","                      min_samples_leaf=2, min_weight_fraction_leaf=0.1,\n","                      splitter='random')"]},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":["# fitting model\n","tuned_hyper_model.fit(X_train,y_train)"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[],"source":["# prediction \n","tuned_pred=tuned_hyper_model.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluating the Performance of Our Model\n","\n","The Linear regression model seem to be overfitting when the testing data create more error than training data.\n"]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 7195.044235459026\n","MSE: 147069244.8879156\n","RMSE: 12127.21092782325\n","Scores: [0.02004596 0.04438509 0.02365256]\n","Mean: 0.0293612043809284\n","Standard deviation: 0.010725039561241267\n"]}],"source":["from sklearn import metrics\n","\n","# Decision tree regressor with MAE, MSE, RMSE results, with hyperparameter tuned \n","print('MAE:', metrics.mean_absolute_error(y_test,tuned_pred))\n","print('MSE:', metrics.mean_squared_error(y_test, tuned_pred))\n","print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, tuned_pred)))\n","\n","# Decsion Tree Regressor with cross validation RMSE score, standard deviaton, with hyperparameter tuned\n","scores = cross_val_score(tuned_hyper_model, X, y, cv=3, scoring='neg_mean_squared_error')\n","display_scores(scores)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('dsenv')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f9b03efc3cc0cdad902fb01df948dfa308c1bba5d284ef31b186b2f65e4ea318"}}},"nbformat":4,"nbformat_minor":2}
