{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **2nd Approach:** Tensorflow Neural Network"]},{"cell_type":"markdown","metadata":{},"source":["### Let's develop a Baseline Neural Network Model using a simple model that has:\n","- A single fully connected hidden layer with the same number of neurons (i.e. 27) as input attributes\n","- A ReLU activation function\n","- A batch normalization layer between two dense layers\n","- Adaptive Moment Estimation (Adam) momentum optimizer"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from time import time\n","import pandas as pd\n","import numpy as np\n","\n","import keras_tuner as kt\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.wrappers.scikit_learn import KerasRegressor\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from keras.models import Sequential \n","from keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout\n","from keras.activations import relu, sigmoid\n","from keras.layers import LeakyReLU\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","\n","\n","%store -r X_train\n","%store -r X_test\n","%store -r y_train\n","%store -r y_test\n","%store -r ind_vars\n","%store -r dep_var\n","%store -r X\n","%store -r y\n","%store -r df"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1751061248.0000\n","Epoch 2/300\n","347/347 [==============================] - 0s 982us/step - loss: 1197266816.0000\n","Epoch 3/300\n","347/347 [==============================] - 0s 1ms/step - loss: 578411456.0000\n","Epoch 4/300\n","347/347 [==============================] - 0s 1ms/step - loss: 251984880.0000\n","Epoch 5/300\n","347/347 [==============================] - 1s 2ms/step - loss: 136592208.0000\n","Epoch 6/300\n","347/347 [==============================] - 0s 1ms/step - loss: 107722320.0000\n","Epoch 7/300\n","347/347 [==============================] - 0s 1ms/step - loss: 94507920.0000\n","Epoch 8/300\n","347/347 [==============================] - 0s 1ms/step - loss: 74968208.0000\n","Epoch 9/300\n","347/347 [==============================] - 0s 1ms/step - loss: 66847996.0000\n","Epoch 10/300\n","347/347 [==============================] - 0s 1ms/step - loss: 68220440.0000\n","Epoch 11/300\n","347/347 [==============================] - 1s 1ms/step - loss: 70570104.0000\n","Epoch 12/300\n","347/347 [==============================] - 0s 1ms/step - loss: 71287560.0000\n","Epoch 13/300\n","347/347 [==============================] - 0s 1ms/step - loss: 64382636.0000\n","Epoch 14/300\n","347/347 [==============================] - 1s 1ms/step - loss: 68425968.0000\n","Epoch 15/300\n","347/347 [==============================] - 0s 1ms/step - loss: 62609620.0000\n","Epoch 16/300\n","347/347 [==============================] - 0s 1ms/step - loss: 60100428.0000\n","Epoch 17/300\n","347/347 [==============================] - 0s 1ms/step - loss: 56298872.0000\n","Epoch 18/300\n","347/347 [==============================] - 0s 1ms/step - loss: 58390596.0000\n","Epoch 19/300\n","347/347 [==============================] - 0s 1ms/step - loss: 59925728.0000\n","Epoch 20/300\n","347/347 [==============================] - 1s 2ms/step - loss: 47627020.0000\n","Epoch 21/300\n","347/347 [==============================] - 1s 2ms/step - loss: 60281020.0000\n","Epoch 22/300\n","347/347 [==============================] - 1s 1ms/step - loss: 54836752.0000\n","Epoch 23/300\n","347/347 [==============================] - 1s 2ms/step - loss: 50795988.0000\n","Epoch 24/300\n","347/347 [==============================] - 1s 2ms/step - loss: 52922504.0000\n","Epoch 25/300\n","347/347 [==============================] - 1s 2ms/step - loss: 56381876.0000\n","Epoch 26/300\n","347/347 [==============================] - 1s 2ms/step - loss: 47833748.0000\n","Epoch 27/300\n","347/347 [==============================] - 0s 977us/step - loss: 48813956.0000\n","Epoch 28/300\n","347/347 [==============================] - 0s 1ms/step - loss: 47421112.0000\n","Epoch 29/300\n","347/347 [==============================] - 0s 1ms/step - loss: 54395472.0000\n","Epoch 30/300\n","347/347 [==============================] - 0s 1ms/step - loss: 48454972.0000\n","Epoch 31/300\n","347/347 [==============================] - 0s 1ms/step - loss: 48183380.0000\n","Epoch 32/300\n","347/347 [==============================] - 0s 1ms/step - loss: 48997912.0000\n","Epoch 33/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44741292.0000\n","Epoch 34/300\n","347/347 [==============================] - 1s 2ms/step - loss: 46550356.0000\n","Epoch 35/300\n","347/347 [==============================] - 0s 1ms/step - loss: 57084400.0000\n","Epoch 36/300\n","347/347 [==============================] - 0s 1ms/step - loss: 48321376.0000\n","Epoch 37/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44979616.0000\n","Epoch 38/300\n","347/347 [==============================] - 1s 1ms/step - loss: 40089488.0000\n","Epoch 39/300\n","347/347 [==============================] - 1s 2ms/step - loss: 44697420.0000\n","Epoch 40/300\n","347/347 [==============================] - 1s 2ms/step - loss: 41041868.0000\n","Epoch 41/300\n","347/347 [==============================] - 0s 1ms/step - loss: 46834752.0000\n","Epoch 42/300\n","347/347 [==============================] - 0s 1ms/step - loss: 51393448.0000\n","Epoch 43/300\n","347/347 [==============================] - 1s 2ms/step - loss: 43891172.0000\n","Epoch 44/300\n","347/347 [==============================] - 1s 2ms/step - loss: 46495436.0000\n","Epoch 45/300\n","347/347 [==============================] - 1s 2ms/step - loss: 50299920.0000\n","Epoch 46/300\n","347/347 [==============================] - 0s 979us/step - loss: 45762428.0000\n","Epoch 47/300\n","347/347 [==============================] - 1s 1ms/step - loss: 48013248.0000\n","Epoch 48/300\n","347/347 [==============================] - 0s 985us/step - loss: 46813296.0000\n","Epoch 49/300\n","347/347 [==============================] - 0s 956us/step - loss: 40233996.0000\n","Epoch 50/300\n","347/347 [==============================] - 0s 971us/step - loss: 44668644.0000\n","Epoch 51/300\n","347/347 [==============================] - 0s 985us/step - loss: 44598552.0000\n","Epoch 52/300\n","347/347 [==============================] - 0s 1ms/step - loss: 48453404.0000\n","Epoch 53/300\n","347/347 [==============================] - 0s 1ms/step - loss: 47243216.0000\n","Epoch 54/300\n","347/347 [==============================] - 0s 977us/step - loss: 42232784.0000\n","Epoch 55/300\n","347/347 [==============================] - 0s 1ms/step - loss: 47743924.0000\n","Epoch 56/300\n","347/347 [==============================] - 0s 1ms/step - loss: 48411532.0000\n","Epoch 57/300\n","347/347 [==============================] - 0s 939us/step - loss: 48016792.0000\n","Epoch 58/300\n","347/347 [==============================] - 1s 2ms/step - loss: 42569396.0000\n","Epoch 59/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42198656.0000\n","Epoch 60/300\n","347/347 [==============================] - 1s 2ms/step - loss: 40271212.0000\n","Epoch 61/300\n","347/347 [==============================] - 1s 3ms/step - loss: 46863516.0000\n","Epoch 62/300\n","347/347 [==============================] - 1s 2ms/step - loss: 45995828.0000\n","Epoch 63/300\n","347/347 [==============================] - 1s 2ms/step - loss: 41737920.0000\n","Epoch 64/300\n","347/347 [==============================] - 1s 2ms/step - loss: 43654780.0000\n","Epoch 65/300\n","347/347 [==============================] - 1s 2ms/step - loss: 41139580.0000\n","Epoch 66/300\n","347/347 [==============================] - 1s 2ms/step - loss: 42471936.0000\n","Epoch 67/300\n","347/347 [==============================] - 1s 2ms/step - loss: 41531316.0000\n","Epoch 68/300\n","347/347 [==============================] - 1s 2ms/step - loss: 45186456.0000\n","Epoch 69/300\n","347/347 [==============================] - 1s 2ms/step - loss: 47952984.0000\n","Epoch 70/300\n","347/347 [==============================] - 1s 2ms/step - loss: 44533440.0000\n","Epoch 71/300\n","347/347 [==============================] - 1s 2ms/step - loss: 42143896.0000\n","Epoch 72/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44977380.0000\n","Epoch 73/300\n","347/347 [==============================] - 1s 1ms/step - loss: 43053000.0000\n","Epoch 74/300\n","347/347 [==============================] - 1s 2ms/step - loss: 42925624.0000\n","Epoch 75/300\n","347/347 [==============================] - 1s 1ms/step - loss: 44177296.0000\n","Epoch 76/300\n","347/347 [==============================] - 0s 1ms/step - loss: 45233368.0000\n","Epoch 77/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41345956.0000\n","Epoch 78/300\n","347/347 [==============================] - 1s 2ms/step - loss: 48510220.0000\n","Epoch 79/300\n","347/347 [==============================] - 1s 2ms/step - loss: 48055032.0000\n","Epoch 80/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44639684.0000\n","Epoch 81/300\n","347/347 [==============================] - 1s 1ms/step - loss: 44293060.0000\n","Epoch 82/300\n","347/347 [==============================] - 1s 1ms/step - loss: 41350464.0000\n","Epoch 83/300\n","347/347 [==============================] - 0s 1ms/step - loss: 50504520.0000\n","Epoch 84/300\n","347/347 [==============================] - 0s 1ms/step - loss: 38779376.0000\n","Epoch 85/300\n","347/347 [==============================] - 0s 1ms/step - loss: 51839732.0000\n","Epoch 86/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44932044.0000\n","Epoch 87/300\n","347/347 [==============================] - 1s 1ms/step - loss: 45955704.0000\n","Epoch 88/300\n","347/347 [==============================] - 0s 1ms/step - loss: 37297324.0000\n","Epoch 89/300\n","347/347 [==============================] - 1s 2ms/step - loss: 39393980.0000\n","Epoch 90/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41006856.0000\n","Epoch 91/300\n","347/347 [==============================] - 1s 1ms/step - loss: 46568816.0000\n","Epoch 92/300\n","347/347 [==============================] - 1s 2ms/step - loss: 43549456.0000\n","Epoch 93/300\n","347/347 [==============================] - 0s 1ms/step - loss: 47223892.0000\n","Epoch 94/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44474448.0000\n","Epoch 95/300\n","347/347 [==============================] - 1s 2ms/step - loss: 37179600.0000\n","Epoch 96/300\n","347/347 [==============================] - 1s 2ms/step - loss: 45822816.0000\n","Epoch 97/300\n","347/347 [==============================] - 1s 2ms/step - loss: 40834272.0000\n","Epoch 98/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41221616.0000\n","Epoch 99/300\n","347/347 [==============================] - 1s 2ms/step - loss: 48177328.0000\n","Epoch 100/300\n","347/347 [==============================] - 1s 2ms/step - loss: 43877928.0000\n","Epoch 101/300\n","347/347 [==============================] - 1s 2ms/step - loss: 43728552.0000\n","Epoch 102/300\n","347/347 [==============================] - 1s 2ms/step - loss: 37988536.0000\n","Epoch 103/300\n","347/347 [==============================] - 1s 2ms/step - loss: 44334896.0000\n","Epoch 104/300\n","347/347 [==============================] - 1s 1ms/step - loss: 44050648.0000\n","Epoch 105/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44900340.0000\n","Epoch 106/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40291376.0000\n","Epoch 107/300\n","347/347 [==============================] - 1s 1ms/step - loss: 41405252.0000\n","Epoch 108/300\n","347/347 [==============================] - 1s 2ms/step - loss: 47375852.0000\n","Epoch 109/300\n","347/347 [==============================] - 1s 2ms/step - loss: 43385268.0000\n","Epoch 110/300\n","347/347 [==============================] - 1s 2ms/step - loss: 46359120.0000\n","Epoch 111/300\n","347/347 [==============================] - 1s 1ms/step - loss: 42159496.0000\n","Epoch 112/300\n","347/347 [==============================] - 1s 2ms/step - loss: 40579856.0000\n","Epoch 113/300\n","347/347 [==============================] - 1s 2ms/step - loss: 40170048.0000\n","Epoch 114/300\n","347/347 [==============================] - 1s 2ms/step - loss: 43286220.0000\n","Epoch 115/300\n","347/347 [==============================] - 0s 1ms/step - loss: 45899116.0000\n","Epoch 116/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40173436.0000\n","Epoch 117/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44431608.0000\n","Epoch 118/300\n","347/347 [==============================] - 0s 1ms/step - loss: 45434196.0000\n","Epoch 119/300\n","347/347 [==============================] - 1s 1ms/step - loss: 43234040.0000\n","Epoch 120/300\n","347/347 [==============================] - 0s 1ms/step - loss: 39969248.0000\n","Epoch 121/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44204388.0000\n","Epoch 122/300\n","347/347 [==============================] - 0s 994us/step - loss: 42705672.0000\n","Epoch 123/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41233440.0000\n","Epoch 124/300\n","347/347 [==============================] - 0s 907us/step - loss: 40199424.0000\n","Epoch 125/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42697868.0000\n","Epoch 126/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41209564.0000\n","Epoch 127/300\n","347/347 [==============================] - 0s 1ms/step - loss: 45273652.0000\n","Epoch 128/300\n","347/347 [==============================] - 0s 965us/step - loss: 47324148.0000\n","Epoch 129/300\n","347/347 [==============================] - 0s 922us/step - loss: 39223516.0000\n","Epoch 130/300\n","347/347 [==============================] - 0s 974us/step - loss: 45740668.0000\n","Epoch 131/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41963788.0000\n","Epoch 132/300\n","347/347 [==============================] - 0s 901us/step - loss: 42417916.0000\n","Epoch 133/300\n","347/347 [==============================] - 0s 982us/step - loss: 41132504.0000\n","Epoch 134/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41634804.0000\n","Epoch 135/300\n","347/347 [==============================] - 0s 1ms/step - loss: 45418176.0000\n","Epoch 136/300\n","347/347 [==============================] - 0s 919us/step - loss: 43876504.0000\n","Epoch 137/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43955064.0000\n","Epoch 138/300\n","347/347 [==============================] - 0s 965us/step - loss: 41254464.0000\n","Epoch 139/300\n","347/347 [==============================] - 0s 979us/step - loss: 40142036.0000\n","Epoch 140/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44734228.0000\n","Epoch 141/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41981260.0000\n","Epoch 142/300\n","347/347 [==============================] - 0s 959us/step - loss: 41861136.0000\n","Epoch 143/300\n","347/347 [==============================] - 0s 925us/step - loss: 40699520.0000\n","Epoch 144/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43010880.0000\n","Epoch 145/300\n","347/347 [==============================] - 0s 1ms/step - loss: 45292164.0000\n","Epoch 146/300\n","347/347 [==============================] - 0s 904us/step - loss: 42816528.0000\n","Epoch 147/300\n","347/347 [==============================] - 0s 1ms/step - loss: 47099772.0000\n","Epoch 148/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44351348.0000\n","Epoch 149/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41630428.0000\n","Epoch 150/300\n","347/347 [==============================] - 1s 2ms/step - loss: 44275192.0000\n","Epoch 151/300\n","347/347 [==============================] - 1s 1ms/step - loss: 52271216.0000\n","Epoch 152/300\n","347/347 [==============================] - 0s 1ms/step - loss: 48210468.0000\n","Epoch 153/300\n","347/347 [==============================] - 0s 1ms/step - loss: 46295368.0000\n","Epoch 154/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43906416.0000\n","Epoch 155/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43247576.0000\n","Epoch 156/300\n","347/347 [==============================] - 0s 1ms/step - loss: 37480356.0000\n","Epoch 157/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43118056.0000\n","Epoch 158/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42821376.0000\n","Epoch 159/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43992028.0000\n","Epoch 160/300\n","347/347 [==============================] - 0s 1ms/step - loss: 38756092.0000\n","Epoch 161/300\n","347/347 [==============================] - 1s 2ms/step - loss: 40709532.0000\n","Epoch 162/300\n","347/347 [==============================] - 1s 2ms/step - loss: 42753680.0000\n","Epoch 163/300\n","347/347 [==============================] - 1s 2ms/step - loss: 43564748.0000\n","Epoch 164/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43584952.0000\n","Epoch 165/300\n","347/347 [==============================] - 0s 1ms/step - loss: 38733428.0000\n","Epoch 166/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43358240.0000\n","Epoch 167/300\n","347/347 [==============================] - 0s 1ms/step - loss: 39472684.0000\n","Epoch 168/300\n","347/347 [==============================] - 0s 1ms/step - loss: 39608468.0000\n","Epoch 169/300\n","347/347 [==============================] - 0s 1ms/step - loss: 46758084.0000\n","Epoch 170/300\n","347/347 [==============================] - 0s 1ms/step - loss: 38528296.0000\n","Epoch 171/300\n","347/347 [==============================] - 0s 1ms/step - loss: 39908292.0000\n","Epoch 172/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41514532.0000\n","Epoch 173/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41413008.0000\n","Epoch 174/300\n","347/347 [==============================] - 1s 1ms/step - loss: 40653912.0000\n","Epoch 175/300\n","347/347 [==============================] - 0s 1ms/step - loss: 38986880.0000\n","Epoch 176/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43483368.0000\n","Epoch 177/300\n","347/347 [==============================] - 1s 2ms/step - loss: 38726580.0000\n","Epoch 178/300\n","347/347 [==============================] - 1s 1ms/step - loss: 40455996.0000\n","Epoch 179/300\n","347/347 [==============================] - 1s 2ms/step - loss: 45068704.0000\n","Epoch 180/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41805980.0000\n","Epoch 181/300\n","347/347 [==============================] - 1s 1ms/step - loss: 40659384.0000\n","Epoch 182/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40820168.0000\n","Epoch 183/300\n","347/347 [==============================] - 0s 1ms/step - loss: 39829560.0000\n","Epoch 184/300\n","347/347 [==============================] - 0s 1ms/step - loss: 38115228.0000\n","Epoch 185/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41173800.0000\n","Epoch 186/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40448320.0000\n","Epoch 187/300\n","347/347 [==============================] - 0s 1ms/step - loss: 39606564.0000\n","Epoch 188/300\n","347/347 [==============================] - 0s 1ms/step - loss: 38323208.0000\n","Epoch 189/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40337472.0000\n","Epoch 190/300\n","347/347 [==============================] - 0s 1ms/step - loss: 36642424.0000\n","Epoch 191/300\n","347/347 [==============================] - 0s 1ms/step - loss: 45759352.0000\n","Epoch 192/300\n","347/347 [==============================] - 1s 2ms/step - loss: 42564820.0000\n","Epoch 193/300\n","347/347 [==============================] - 1s 1ms/step - loss: 41302580.0000\n","Epoch 194/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42343672.0000\n","Epoch 195/300\n","347/347 [==============================] - 0s 1ms/step - loss: 48261744.0000\n","Epoch 196/300\n","347/347 [==============================] - 0s 1ms/step - loss: 47747800.0000\n","Epoch 197/300\n","347/347 [==============================] - 0s 1ms/step - loss: 39234060.0000\n","Epoch 198/300\n","347/347 [==============================] - 0s 1ms/step - loss: 37379708.0000\n","Epoch 199/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40385552.0000\n","Epoch 200/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41790500.0000\n","Epoch 201/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41630408.0000\n","Epoch 202/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44971028.0000\n","Epoch 203/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40986544.0000\n","Epoch 204/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44945300.0000\n","Epoch 205/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44210196.0000\n","Epoch 206/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41939988.0000\n","Epoch 207/300\n","347/347 [==============================] - 0s 1ms/step - loss: 39975160.0000\n","Epoch 208/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44951356.0000\n","Epoch 209/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40153520.0000\n","Epoch 210/300\n","347/347 [==============================] - 0s 1ms/step - loss: 37835896.0000\n","Epoch 211/300\n","347/347 [==============================] - 1s 1ms/step - loss: 45121316.0000\n","Epoch 212/300\n","347/347 [==============================] - 0s 1ms/step - loss: 45312688.0000\n","Epoch 213/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42663252.0000\n","Epoch 214/300\n","347/347 [==============================] - 0s 1ms/step - loss: 50401004.0000\n","Epoch 215/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42718724.0000\n","Epoch 216/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42072016.0000\n","Epoch 217/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43456424.0000\n","Epoch 218/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40308400.0000\n","Epoch 219/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42646644.0000\n","Epoch 220/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44002680.0000\n","Epoch 221/300\n","347/347 [==============================] - 1s 1ms/step - loss: 41336076.0000\n","Epoch 222/300\n","347/347 [==============================] - 0s 1ms/step - loss: 34317132.0000\n","Epoch 223/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41654404.0000\n","Epoch 224/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42648872.0000\n","Epoch 225/300\n","347/347 [==============================] - 1s 1ms/step - loss: 42261892.0000\n","Epoch 226/300\n","347/347 [==============================] - 1s 2ms/step - loss: 40368048.0000\n","Epoch 227/300\n","347/347 [==============================] - 1s 2ms/step - loss: 42220900.0000\n","Epoch 228/300\n","347/347 [==============================] - 1s 1ms/step - loss: 38098684.0000\n","Epoch 229/300\n","347/347 [==============================] - 1s 2ms/step - loss: 43448676.0000\n","Epoch 230/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43655804.0000\n","Epoch 231/300\n","347/347 [==============================] - 1s 1ms/step - loss: 40905676.0000\n","Epoch 232/300\n","347/347 [==============================] - 0s 1ms/step - loss: 37512348.0000\n","Epoch 233/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40608620.0000\n","Epoch 234/300\n","347/347 [==============================] - 1s 2ms/step - loss: 42929380.0000\n","Epoch 235/300\n","347/347 [==============================] - 1s 2ms/step - loss: 40703560.0000\n","Epoch 236/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40909980.0000\n","Epoch 237/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42453208.0000\n","Epoch 238/300\n","347/347 [==============================] - 0s 1ms/step - loss: 45076196.0000\n","Epoch 239/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44187756.0000\n","Epoch 240/300\n","347/347 [==============================] - 0s 1ms/step - loss: 39512336.0000\n","Epoch 241/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43123476.0000\n","Epoch 242/300\n","347/347 [==============================] - 1s 2ms/step - loss: 44230188.0000\n","Epoch 243/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40370732.0000\n","Epoch 244/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42775736.0000\n","Epoch 245/300\n","347/347 [==============================] - 1s 2ms/step - loss: 45890576.0000\n","Epoch 246/300\n","347/347 [==============================] - 0s 1ms/step - loss: 46005148.0000\n","Epoch 247/300\n","347/347 [==============================] - 1s 2ms/step - loss: 42702892.0000\n","Epoch 248/300\n","347/347 [==============================] - 1s 2ms/step - loss: 40748980.0000\n","Epoch 249/300\n","347/347 [==============================] - 1s 2ms/step - loss: 44647936.0000\n","Epoch 250/300\n","347/347 [==============================] - 1s 2ms/step - loss: 43452900.0000\n","Epoch 251/300\n","347/347 [==============================] - 1s 2ms/step - loss: 40926900.0000\n","Epoch 252/300\n","347/347 [==============================] - 1s 2ms/step - loss: 41905460.0000\n","Epoch 253/300\n","347/347 [==============================] - 1s 2ms/step - loss: 41438584.0000\n","Epoch 254/300\n","347/347 [==============================] - 1s 2ms/step - loss: 45379464.0000\n","Epoch 255/300\n","347/347 [==============================] - 1s 2ms/step - loss: 43863984.0000\n","Epoch 256/300\n","347/347 [==============================] - 1s 2ms/step - loss: 39520008.0000\n","Epoch 257/300\n","347/347 [==============================] - 0s 1ms/step - loss: 46134848.0000\n","Epoch 258/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44689504.0000\n","Epoch 259/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43561080.0000\n","Epoch 260/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42070444.0000\n","Epoch 261/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43989528.0000\n","Epoch 262/300\n","347/347 [==============================] - 0s 1ms/step - loss: 39911612.0000\n","Epoch 263/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44685256.0000\n","Epoch 264/300\n","347/347 [==============================] - 0s 1ms/step - loss: 36198556.0000\n","Epoch 265/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42013956.0000\n","Epoch 266/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40158848.0000\n","Epoch 267/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42065800.0000\n","Epoch 268/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41458060.0000\n","Epoch 269/300\n","347/347 [==============================] - 1s 2ms/step - loss: 42507488.0000\n","Epoch 270/300\n","347/347 [==============================] - 0s 1ms/step - loss: 39556916.0000\n","Epoch 271/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40196188.0000\n","Epoch 272/300\n","347/347 [==============================] - 0s 1ms/step - loss: 38630744.0000\n","Epoch 273/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44640604.0000\n","Epoch 274/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43918888.0000\n","Epoch 275/300\n","347/347 [==============================] - 0s 1ms/step - loss: 46232600.0000\n","Epoch 276/300\n","347/347 [==============================] - 0s 1ms/step - loss: 46420540.0000\n","Epoch 277/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42634148.0000\n","Epoch 278/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41897844.0000\n","Epoch 279/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42147352.0000\n","Epoch 280/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40784984.0000\n","Epoch 281/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41730928.0000\n","Epoch 282/300\n","347/347 [==============================] - 0s 1ms/step - loss: 37061152.0000\n","Epoch 283/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44299688.0000\n","Epoch 284/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43803184.0000\n","Epoch 285/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44043376.0000\n","Epoch 286/300\n","347/347 [==============================] - 0s 1ms/step - loss: 43238012.0000\n","Epoch 287/300\n","347/347 [==============================] - 1s 1ms/step - loss: 41969984.0000\n","Epoch 288/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44501648.0000\n","Epoch 289/300\n","347/347 [==============================] - 0s 1ms/step - loss: 37648004.0000\n","Epoch 290/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42325104.0000\n","Epoch 291/300\n","347/347 [==============================] - 0s 1ms/step - loss: 37306728.0000\n","Epoch 292/300\n","347/347 [==============================] - 0s 1ms/step - loss: 42557508.0000\n","Epoch 293/300\n","347/347 [==============================] - 0s 1ms/step - loss: 49387804.0000\n","Epoch 294/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44849996.0000\n","Epoch 295/300\n","347/347 [==============================] - 0s 1ms/step - loss: 39926932.0000\n","Epoch 296/300\n","347/347 [==============================] - 0s 1ms/step - loss: 44585100.0000\n","Epoch 297/300\n","347/347 [==============================] - 0s 1ms/step - loss: 38910876.0000\n","Epoch 298/300\n","347/347 [==============================] - 1s 2ms/step - loss: 36131336.0000\n","Epoch 299/300\n","347/347 [==============================] - 0s 1ms/step - loss: 41272100.0000\n","Epoch 300/300\n","347/347 [==============================] - 0s 1ms/step - loss: 40444972.0000\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_4 (Dense)             (None, 30)                930       \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 30)               120       \n"," hNormalization)                                                 \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 31        \n","                                                                 \n","=================================================================\n","Total params: 1,081\n","Trainable params: 1,021\n","Non-trainable params: 60\n","_________________________________________________________________\n","87/87 [==============================] - 0s 953us/step\n","[[20779.227  ]\n"," [ 6040.292  ]\n"," [ 3582.7268 ]\n"," ...\n"," [10415.013  ]\n"," [  781.91345]\n"," [10317.412  ]]\n"]}],"source":["tf.random.set_seed(45)\n","\n","#define baseline model\n","model = keras.models.Sequential([\n","    keras.layers.Dense(30, input_shape=(30,), activation=\"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(1)\n","])\n","model.compile(loss='mean_squared_error', optimizer= tf.keras.optimizers.Adam(0.02))\n","\n","#fit model\n","history = model.fit(X_train, y_train, epochs= 300)\n","model.summary()\n","\n","#test model\n","print(model.predict(X_test))"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[25005.]\n"," [ 9664.]\n"," [ 6053.]\n"," ...\n"," [12549.]\n"," [ 1204.]\n"," [13000.]]\n"]}],"source":["print(y_test)"]},{"cell_type":"markdown","metadata":{},"source":["## Automatic Hyperparamater Tuning"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def model_builder(hp):\n","  # Initialize the Sequential API and start stacking the layers\n","  # Tune the number of units in the first Dense layer\n","  # Choose an optimal value between 32-512\n","  hp_units = hp.Int('units', min_value=30, max_value=30)\n","  model = keras.models.Sequential([\n","      keras.layers.Dense(input_shape=(30,), units=hp_units, activation='relu'),\n","      # Add next layers\n","      keras.layers.BatchNormalization(),\n","      keras.layers.Dense(1)\n","  ])\n","      # Tune the learning rate for the optimizer\n","  # Choose an optimal value from 0.01, 0.001, or 0.0001\n","  hp_learning_rate = hp.Choice('learning_rate', values=[2e-1, 2e-2, 2e-3, 2e-4])\n","  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n","                loss='mean_squared_error',\n","                metrics=['accuracy'])\n","  return model"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n","INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n","INFO:tensorflow:Oracle triggered exit\n"]}],"source":["tf.random.set_seed(45)\n","\n","# Instantiate the tuner\n","tuner = kt.Hyperband(model_builder, # the hypermodel\n","                     objective='val_accuracy', # objective to optimize\n","max_epochs=300,\n",")\n","\n","# Perform hypertuning\n","tuner.search(X_train, y_train, epochs=300, validation_split=0.2)\n","best_hp=tuner.get_best_hyperparameters()[0]"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# Build the model with the optimal hyperparameters\n","h_model = tuner.hypermodel.build(best_hp)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1858345088.0000 - accuracy: 0.0000e+00\n","Epoch 2/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1858015488.0000 - accuracy: 0.0000e+00\n","Epoch 3/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1857639680.0000 - accuracy: 0.0000e+00\n","Epoch 4/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1857226496.0000 - accuracy: 0.0000e+00\n","Epoch 5/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1856762752.0000 - accuracy: 0.0000e+00\n","Epoch 6/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1856273280.0000 - accuracy: 0.0000e+00\n","Epoch 7/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1855737984.0000 - accuracy: 0.0000e+00\n","Epoch 8/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1855111424.0000 - accuracy: 0.0000e+00\n","Epoch 9/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1854476416.0000 - accuracy: 0.0000e+00\n","Epoch 10/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1853831296.0000 - accuracy: 0.0000e+00\n","Epoch 11/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1853151488.0000 - accuracy: 0.0000e+00\n","Epoch 12/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1852436864.0000 - accuracy: 0.0000e+00\n","Epoch 13/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1851655552.0000 - accuracy: 0.0000e+00\n","Epoch 14/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1850765696.0000 - accuracy: 0.0000e+00\n","Epoch 15/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1849871744.0000 - accuracy: 0.0000e+00\n","Epoch 16/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1848957824.0000 - accuracy: 0.0000e+00\n","Epoch 17/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1848019200.0000 - accuracy: 0.0000e+00\n","Epoch 18/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1847071360.0000 - accuracy: 0.0000e+00\n","Epoch 19/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1846112896.0000 - accuracy: 0.0000e+00\n","Epoch 20/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1845027072.0000 - accuracy: 0.0000e+00\n","Epoch 21/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1844075904.0000 - accuracy: 0.0000e+00\n","Epoch 22/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1842947712.0000 - accuracy: 0.0000e+00\n","Epoch 23/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1841799424.0000 - accuracy: 0.0000e+00\n","Epoch 24/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1840673664.0000 - accuracy: 0.0000e+00\n","Epoch 25/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1839511168.0000 - accuracy: 0.0000e+00\n","Epoch 26/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1838235392.0000 - accuracy: 0.0000e+00\n","Epoch 27/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1836987264.0000 - accuracy: 0.0000e+00\n","Epoch 28/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1835655936.0000 - accuracy: 0.0000e+00\n","Epoch 29/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1834459904.0000 - accuracy: 0.0000e+00\n","Epoch 30/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1833048960.0000 - accuracy: 0.0000e+00\n","Epoch 31/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1831626624.0000 - accuracy: 0.0000e+00\n","Epoch 32/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1830285568.0000 - accuracy: 0.0000e+00\n","Epoch 33/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1828769024.0000 - accuracy: 0.0000e+00\n","Epoch 34/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1827303808.0000 - accuracy: 0.0000e+00\n","Epoch 35/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1825992832.0000 - accuracy: 0.0000e+00\n","Epoch 36/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1824268032.0000 - accuracy: 0.0000e+00\n","Epoch 37/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1822627712.0000 - accuracy: 0.0000e+00\n","Epoch 38/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1820958464.0000 - accuracy: 0.0000e+00\n","Epoch 39/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1819437568.0000 - accuracy: 0.0000e+00\n","Epoch 40/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1817705600.0000 - accuracy: 0.0000e+00\n","Epoch 41/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1816058368.0000 - accuracy: 0.0000e+00\n","Epoch 42/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1814468352.0000 - accuracy: 0.0000e+00\n","Epoch 43/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1812494592.0000 - accuracy: 0.0000e+00\n","Epoch 44/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1810754304.0000 - accuracy: 0.0000e+00\n","Epoch 45/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1809071872.0000 - accuracy: 0.0000e+00\n","Epoch 46/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1807131520.0000 - accuracy: 0.0000e+00\n","Epoch 47/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1805219072.0000 - accuracy: 0.0000e+00\n","Epoch 48/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1803330944.0000 - accuracy: 0.0000e+00\n","Epoch 49/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1801198464.0000 - accuracy: 0.0000e+00\n","Epoch 50/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1799285504.0000 - accuracy: 0.0000e+00\n","Epoch 51/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1797269504.0000 - accuracy: 0.0000e+00\n","Epoch 52/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1795366784.0000 - accuracy: 0.0000e+00\n","Epoch 53/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1793191040.0000 - accuracy: 0.0000e+00\n","Epoch 54/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1790983168.0000 - accuracy: 0.0000e+00\n","Epoch 55/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1789084032.0000 - accuracy: 0.0000e+00\n","Epoch 56/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1787022208.0000 - accuracy: 0.0000e+00\n","Epoch 57/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1784580096.0000 - accuracy: 0.0000e+00\n","Epoch 58/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1782191616.0000 - accuracy: 0.0000e+00\n","Epoch 59/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1780010112.0000 - accuracy: 0.0000e+00\n","Epoch 60/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1777562752.0000 - accuracy: 0.0000e+00\n","Epoch 61/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1775607680.0000 - accuracy: 0.0000e+00\n","Epoch 62/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1773118720.0000 - accuracy: 0.0000e+00\n","Epoch 63/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1770561408.0000 - accuracy: 0.0000e+00\n","Epoch 64/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1768353152.0000 - accuracy: 0.0000e+00\n","Epoch 65/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1765789312.0000 - accuracy: 0.0000e+00\n","Epoch 66/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1763335680.0000 - accuracy: 0.0000e+00\n","Epoch 67/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1760813440.0000 - accuracy: 0.0000e+00\n","Epoch 68/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1758409984.0000 - accuracy: 0.0000e+00\n","Epoch 69/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1755963776.0000 - accuracy: 0.0000e+00\n","Epoch 70/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1753360256.0000 - accuracy: 0.0000e+00\n","Epoch 71/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1750451584.0000 - accuracy: 0.0000e+00\n","Epoch 72/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1748105472.0000 - accuracy: 0.0000e+00\n","Epoch 73/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1745362304.0000 - accuracy: 0.0000e+00\n","Epoch 74/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1742389120.0000 - accuracy: 0.0000e+00\n","Epoch 75/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1739872640.0000 - accuracy: 0.0000e+00\n","Epoch 76/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1737119232.0000 - accuracy: 0.0000e+00\n","Epoch 77/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1734182144.0000 - accuracy: 0.0000e+00\n","Epoch 78/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1731757312.0000 - accuracy: 0.0000e+00\n","Epoch 79/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1729022080.0000 - accuracy: 0.0000e+00\n","Epoch 80/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1725827200.0000 - accuracy: 0.0000e+00\n","Epoch 81/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1723050240.0000 - accuracy: 0.0000e+00\n","Epoch 82/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1719854976.0000 - accuracy: 0.0000e+00\n","Epoch 83/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1717621760.0000 - accuracy: 0.0000e+00\n","Epoch 84/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1713784320.0000 - accuracy: 0.0000e+00\n","Epoch 85/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1711691264.0000 - accuracy: 0.0000e+00\n","Epoch 86/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1708149632.0000 - accuracy: 0.0000e+00\n","Epoch 87/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1705139712.0000 - accuracy: 0.0000e+00\n","Epoch 88/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1701283200.0000 - accuracy: 0.0000e+00\n","Epoch 89/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1698390912.0000 - accuracy: 0.0000e+00\n","Epoch 90/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1695410048.0000 - accuracy: 0.0000e+00\n","Epoch 91/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1692618624.0000 - accuracy: 0.0000e+00\n","Epoch 92/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1689174272.0000 - accuracy: 0.0000e+00\n","Epoch 93/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1686354944.0000 - accuracy: 0.0000e+00\n","Epoch 94/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1682987136.0000 - accuracy: 0.0000e+00\n","Epoch 95/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1679045760.0000 - accuracy: 0.0000e+00\n","Epoch 96/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1676260224.0000 - accuracy: 0.0000e+00\n","Epoch 97/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1672496896.0000 - accuracy: 0.0000e+00\n","Epoch 98/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1669345280.0000 - accuracy: 0.0000e+00\n","Epoch 99/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1666477568.0000 - accuracy: 0.0000e+00\n","Epoch 100/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1662594176.0000 - accuracy: 0.0000e+00\n","Epoch 101/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1659169280.0000 - accuracy: 0.0000e+00\n","Epoch 102/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1655115392.0000 - accuracy: 0.0000e+00\n","Epoch 103/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1652273920.0000 - accuracy: 0.0000e+00\n","Epoch 104/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1648852096.0000 - accuracy: 0.0000e+00\n","Epoch 105/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1645485056.0000 - accuracy: 0.0000e+00\n","Epoch 106/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1641203584.0000 - accuracy: 0.0000e+00\n","Epoch 107/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1637908608.0000 - accuracy: 0.0000e+00\n","Epoch 108/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1635031808.0000 - accuracy: 0.0000e+00\n","Epoch 109/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1631231744.0000 - accuracy: 0.0000e+00\n","Epoch 110/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1627529216.0000 - accuracy: 0.0000e+00\n","Epoch 111/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1623529600.0000 - accuracy: 0.0000e+00\n","Epoch 112/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1619315456.0000 - accuracy: 0.0000e+00\n","Epoch 113/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1615599360.0000 - accuracy: 0.0000e+00\n","Epoch 114/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1612077440.0000 - accuracy: 0.0000e+00\n","Epoch 115/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1608976128.0000 - accuracy: 0.0000e+00\n","Epoch 116/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1603847808.0000 - accuracy: 0.0000e+00\n","Epoch 117/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1600421632.0000 - accuracy: 0.0000e+00\n","Epoch 118/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1597235968.0000 - accuracy: 0.0000e+00\n","Epoch 119/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1593040256.0000 - accuracy: 0.0000e+00\n","Epoch 120/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1588443008.0000 - accuracy: 0.0000e+00\n","Epoch 121/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1585254656.0000 - accuracy: 0.0000e+00\n","Epoch 122/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1581016704.0000 - accuracy: 0.0000e+00\n","Epoch 123/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1576888576.0000 - accuracy: 0.0000e+00\n","Epoch 124/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1572750848.0000 - accuracy: 0.0000e+00\n","Epoch 125/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1569112192.0000 - accuracy: 0.0000e+00\n","Epoch 126/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1564752512.0000 - accuracy: 0.0000e+00\n","Epoch 127/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1561231488.0000 - accuracy: 0.0000e+00\n","Epoch 128/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1557936128.0000 - accuracy: 0.0000e+00\n","Epoch 129/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1552625536.0000 - accuracy: 0.0000e+00\n","Epoch 130/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1548797440.0000 - accuracy: 0.0000e+00\n","Epoch 131/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1544019840.0000 - accuracy: 0.0000e+00\n","Epoch 132/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1540240640.0000 - accuracy: 0.0000e+00\n","Epoch 133/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1535842944.0000 - accuracy: 0.0000e+00\n","Epoch 134/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1531908736.0000 - accuracy: 0.0000e+00\n","Epoch 135/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1528231936.0000 - accuracy: 0.0000e+00\n","Epoch 136/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1523696768.0000 - accuracy: 0.0000e+00\n","Epoch 137/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1519722752.0000 - accuracy: 0.0000e+00\n","Epoch 138/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1514546432.0000 - accuracy: 0.0000e+00\n","Epoch 139/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1510177408.0000 - accuracy: 0.0000e+00\n","Epoch 140/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1506317440.0000 - accuracy: 0.0000e+00\n","Epoch 141/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1501979776.0000 - accuracy: 0.0000e+00\n","Epoch 142/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1497364608.0000 - accuracy: 0.0000e+00\n","Epoch 143/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1492327808.0000 - accuracy: 0.0000e+00\n","Epoch 144/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1488492800.0000 - accuracy: 0.0000e+00\n","Epoch 145/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1484947200.0000 - accuracy: 0.0000e+00\n","Epoch 146/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1479668096.0000 - accuracy: 0.0000e+00\n","Epoch 147/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1475901312.0000 - accuracy: 0.0000e+00\n","Epoch 148/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1470664832.0000 - accuracy: 0.0000e+00\n","Epoch 149/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1465890816.0000 - accuracy: 0.0000e+00\n","Epoch 150/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1461594880.0000 - accuracy: 0.0000e+00\n","Epoch 151/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1458762368.0000 - accuracy: 0.0000e+00\n","Epoch 152/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1453805568.0000 - accuracy: 0.0000e+00\n","Epoch 153/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1448718976.0000 - accuracy: 0.0000e+00\n","Epoch 154/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1443847424.0000 - accuracy: 0.0000e+00\n","Epoch 155/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1438818048.0000 - accuracy: 0.0000e+00\n","Epoch 156/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1433100544.0000 - accuracy: 0.0000e+00\n","Epoch 157/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1429627264.0000 - accuracy: 0.0000e+00\n","Epoch 158/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1424704256.0000 - accuracy: 0.0000e+00\n","Epoch 159/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1420184832.0000 - accuracy: 0.0000e+00\n","Epoch 160/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1414499072.0000 - accuracy: 0.0000e+00\n","Epoch 161/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1410456576.0000 - accuracy: 0.0000e+00\n","Epoch 162/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1405754624.0000 - accuracy: 0.0000e+00\n","Epoch 163/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1401151872.0000 - accuracy: 0.0000e+00\n","Epoch 164/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1396482560.0000 - accuracy: 0.0000e+00\n","Epoch 165/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1390379136.0000 - accuracy: 0.0000e+00\n","Epoch 166/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1386110848.0000 - accuracy: 0.0000e+00\n","Epoch 167/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1380337408.0000 - accuracy: 0.0000e+00\n","Epoch 168/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1376218752.0000 - accuracy: 0.0000e+00\n","Epoch 169/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1372425728.0000 - accuracy: 0.0000e+00\n","Epoch 170/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1365878272.0000 - accuracy: 0.0000e+00\n","Epoch 171/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1361710848.0000 - accuracy: 0.0000e+00\n","Epoch 172/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1356901248.0000 - accuracy: 0.0000e+00\n","Epoch 173/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1351948032.0000 - accuracy: 0.0000e+00\n","Epoch 174/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1347129088.0000 - accuracy: 0.0000e+00\n","Epoch 175/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1341318272.0000 - accuracy: 0.0000e+00\n","Epoch 176/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1337673984.0000 - accuracy: 0.0000e+00\n","Epoch 177/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1331532160.0000 - accuracy: 0.0000e+00\n","Epoch 178/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1326032512.0000 - accuracy: 0.0000e+00\n","Epoch 179/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1323097728.0000 - accuracy: 0.0000e+00\n","Epoch 180/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1316740736.0000 - accuracy: 0.0000e+00\n","Epoch 181/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1312035840.0000 - accuracy: 0.0000e+00\n","Epoch 182/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1306590080.0000 - accuracy: 0.0000e+00\n","Epoch 183/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1300731392.0000 - accuracy: 0.0000e+00\n","Epoch 184/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1295753344.0000 - accuracy: 0.0000e+00\n","Epoch 185/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1291091200.0000 - accuracy: 0.0000e+00\n","Epoch 186/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1285691648.0000 - accuracy: 0.0000e+00\n","Epoch 187/300\n","347/347 [==============================] - 1s 1ms/step - loss: 1280029824.0000 - accuracy: 0.0000e+00\n","Epoch 188/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1275480192.0000 - accuracy: 0.0000e+00\n","Epoch 189/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1270160128.0000 - accuracy: 0.0000e+00\n","Epoch 190/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1263968768.0000 - accuracy: 0.0000e+00\n","Epoch 191/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1260865152.0000 - accuracy: 0.0000e+00\n","Epoch 192/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1255571456.0000 - accuracy: 0.0000e+00\n","Epoch 193/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1250209792.0000 - accuracy: 0.0000e+00\n","Epoch 194/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1245442304.0000 - accuracy: 0.0000e+00\n","Epoch 195/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1242394496.0000 - accuracy: 0.0000e+00\n","Epoch 196/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1236686464.0000 - accuracy: 0.0000e+00\n","Epoch 197/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1228917888.0000 - accuracy: 0.0000e+00\n","Epoch 198/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1222865024.0000 - accuracy: 0.0000e+00\n","Epoch 199/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1218250240.0000 - accuracy: 0.0000e+00\n","Epoch 200/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1213001600.0000 - accuracy: 0.0000e+00\n","Epoch 201/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1207607296.0000 - accuracy: 0.0000e+00\n","Epoch 202/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1204181888.0000 - accuracy: 0.0000e+00\n","Epoch 203/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1196801408.0000 - accuracy: 0.0000e+00\n","Epoch 204/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1193124608.0000 - accuracy: 0.0000e+00\n","Epoch 205/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1187252864.0000 - accuracy: 0.0000e+00\n","Epoch 206/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1181364736.0000 - accuracy: 0.0000e+00\n","Epoch 207/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1175533056.0000 - accuracy: 0.0000e+00\n","Epoch 208/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1172249344.0000 - accuracy: 0.0000e+00\n","Epoch 209/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1164750080.0000 - accuracy: 0.0000e+00\n","Epoch 210/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1159011072.0000 - accuracy: 0.0000e+00\n","Epoch 211/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1155300992.0000 - accuracy: 0.0000e+00\n","Epoch 212/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1150110080.0000 - accuracy: 0.0000e+00\n","Epoch 213/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1144511872.0000 - accuracy: 0.0000e+00\n","Epoch 214/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1140510976.0000 - accuracy: 0.0000e+00\n","Epoch 215/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1133602560.0000 - accuracy: 0.0000e+00\n","Epoch 216/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1127708160.0000 - accuracy: 0.0000e+00\n","Epoch 217/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1122586240.0000 - accuracy: 0.0000e+00\n","Epoch 218/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1115639040.0000 - accuracy: 0.0000e+00\n","Epoch 219/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1111660800.0000 - accuracy: 0.0000e+00\n","Epoch 220/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1107053440.0000 - accuracy: 0.0000e+00\n","Epoch 221/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1100626944.0000 - accuracy: 0.0000e+00\n","Epoch 222/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1092411648.0000 - accuracy: 0.0000e+00\n","Epoch 223/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1089588736.0000 - accuracy: 0.0000e+00\n","Epoch 224/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1083576832.0000 - accuracy: 0.0000e+00\n","Epoch 225/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1078133888.0000 - accuracy: 0.0000e+00\n","Epoch 226/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1072403008.0000 - accuracy: 0.0000e+00\n","Epoch 227/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1068504896.0000 - accuracy: 0.0000e+00\n","Epoch 228/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1061554048.0000 - accuracy: 0.0000e+00\n","Epoch 229/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1057327296.0000 - accuracy: 0.0000e+00\n","Epoch 230/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1051535104.0000 - accuracy: 0.0000e+00\n","Epoch 231/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1045644864.0000 - accuracy: 0.0000e+00\n","Epoch 232/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1037704320.0000 - accuracy: 0.0000e+00\n","Epoch 233/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1033927616.0000 - accuracy: 0.0000e+00\n","Epoch 234/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1028753856.0000 - accuracy: 0.0000e+00\n","Epoch 235/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1023148992.0000 - accuracy: 0.0000e+00\n","Epoch 236/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1017919616.0000 - accuracy: 0.0000e+00\n","Epoch 237/300\n","347/347 [==============================] - 0s 1ms/step - loss: 1012328704.0000 - accuracy: 0.0000e+00\n","Epoch 238/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1008528512.0000 - accuracy: 0.0000e+00\n","Epoch 239/300\n","347/347 [==============================] - 1s 2ms/step - loss: 1003277824.0000 - accuracy: 0.0000e+00\n","Epoch 240/300\n","347/347 [==============================] - 1s 2ms/step - loss: 995383936.0000 - accuracy: 0.0000e+00\n","Epoch 241/300\n","347/347 [==============================] - 0s 1ms/step - loss: 992825536.0000 - accuracy: 0.0000e+00\n","Epoch 242/300\n","347/347 [==============================] - 1s 2ms/step - loss: 985865728.0000 - accuracy: 0.0000e+00\n","Epoch 243/300\n","347/347 [==============================] - 1s 1ms/step - loss: 978194880.0000 - accuracy: 0.0000e+00\n","Epoch 244/300\n","347/347 [==============================] - 1s 2ms/step - loss: 974785024.0000 - accuracy: 0.0000e+00\n","Epoch 245/300\n","347/347 [==============================] - 1s 2ms/step - loss: 971079296.0000 - accuracy: 0.0000e+00\n","Epoch 246/300\n","347/347 [==============================] - 1s 2ms/step - loss: 966275712.0000 - accuracy: 0.0000e+00\n","Epoch 247/300\n","347/347 [==============================] - 1s 2ms/step - loss: 957203904.0000 - accuracy: 0.0000e+00\n","Epoch 248/300\n","347/347 [==============================] - 1s 2ms/step - loss: 952196480.0000 - accuracy: 0.0000e+00\n","Epoch 249/300\n","347/347 [==============================] - 1s 2ms/step - loss: 948224768.0000 - accuracy: 0.0000e+00\n","Epoch 250/300\n","347/347 [==============================] - 1s 2ms/step - loss: 941856640.0000 - accuracy: 0.0000e+00\n","Epoch 251/300\n","347/347 [==============================] - 1s 2ms/step - loss: 934079936.0000 - accuracy: 0.0000e+00\n","Epoch 252/300\n","347/347 [==============================] - 1s 2ms/step - loss: 929931584.0000 - accuracy: 0.0000e+00\n","Epoch 253/300\n","347/347 [==============================] - 1s 1ms/step - loss: 924413888.0000 - accuracy: 0.0000e+00\n","Epoch 254/300\n","347/347 [==============================] - 1s 2ms/step - loss: 921365760.0000 - accuracy: 0.0000e+00\n","Epoch 255/300\n","347/347 [==============================] - 1s 1ms/step - loss: 915312832.0000 - accuracy: 0.0000e+00\n","Epoch 256/300\n","347/347 [==============================] - 0s 1ms/step - loss: 907286592.0000 - accuracy: 0.0000e+00\n","Epoch 257/300\n","347/347 [==============================] - 1s 1ms/step - loss: 903848384.0000 - accuracy: 0.0000e+00\n","Epoch 258/300\n","347/347 [==============================] - 0s 1ms/step - loss: 897617280.0000 - accuracy: 0.0000e+00\n","Epoch 259/300\n","347/347 [==============================] - 0s 1ms/step - loss: 890949120.0000 - accuracy: 0.0000e+00\n","Epoch 260/300\n","347/347 [==============================] - 0s 1ms/step - loss: 885705600.0000 - accuracy: 0.0000e+00\n","Epoch 261/300\n","347/347 [==============================] - 0s 1ms/step - loss: 881751616.0000 - accuracy: 0.0000e+00\n","Epoch 262/300\n","347/347 [==============================] - 1s 1ms/step - loss: 874013696.0000 - accuracy: 0.0000e+00\n","Epoch 263/300\n","347/347 [==============================] - 0s 1ms/step - loss: 872552832.0000 - accuracy: 0.0000e+00\n","Epoch 264/300\n","347/347 [==============================] - 0s 1ms/step - loss: 860867840.0000 - accuracy: 0.0000e+00\n","Epoch 265/300\n","347/347 [==============================] - 0s 1ms/step - loss: 858615424.0000 - accuracy: 0.0000e+00\n","Epoch 266/300\n","347/347 [==============================] - 1s 2ms/step - loss: 852000128.0000 - accuracy: 0.0000e+00\n","Epoch 267/300\n","347/347 [==============================] - 1s 2ms/step - loss: 847157056.0000 - accuracy: 0.0000e+00\n","Epoch 268/300\n","347/347 [==============================] - 1s 2ms/step - loss: 840975808.0000 - accuracy: 0.0000e+00\n","Epoch 269/300\n","347/347 [==============================] - 1s 2ms/step - loss: 836531392.0000 - accuracy: 0.0000e+00\n","Epoch 270/300\n","347/347 [==============================] - 1s 2ms/step - loss: 828778368.0000 - accuracy: 0.0000e+00\n","Epoch 271/300\n","347/347 [==============================] - 1s 2ms/step - loss: 826187712.0000 - accuracy: 0.0000e+00\n","Epoch 272/300\n","347/347 [==============================] - 1s 2ms/step - loss: 818302272.0000 - accuracy: 0.0000e+00\n","Epoch 273/300\n","347/347 [==============================] - 1s 2ms/step - loss: 817440128.0000 - accuracy: 0.0000e+00\n","Epoch 274/300\n","347/347 [==============================] - 1s 2ms/step - loss: 810361408.0000 - accuracy: 0.0000e+00\n","Epoch 275/300\n","347/347 [==============================] - 1s 2ms/step - loss: 806014336.0000 - accuracy: 0.0000e+00\n","Epoch 276/300\n","347/347 [==============================] - 1s 2ms/step - loss: 801149760.0000 - accuracy: 0.0000e+00\n","Epoch 277/300\n","347/347 [==============================] - 1s 2ms/step - loss: 793328896.0000 - accuracy: 0.0000e+00\n","Epoch 278/300\n","347/347 [==============================] - 1s 2ms/step - loss: 787036736.0000 - accuracy: 0.0000e+00\n","Epoch 279/300\n","347/347 [==============================] - 1s 2ms/step - loss: 782609600.0000 - accuracy: 0.0000e+00\n","Epoch 280/300\n","347/347 [==============================] - 1s 2ms/step - loss: 775420608.0000 - accuracy: 0.0000e+00\n","Epoch 281/300\n","347/347 [==============================] - 1s 2ms/step - loss: 771031104.0000 - accuracy: 0.0000e+00\n","Epoch 282/300\n","347/347 [==============================] - 1s 2ms/step - loss: 765155072.0000 - accuracy: 0.0000e+00\n","Epoch 283/300\n","347/347 [==============================] - 1s 2ms/step - loss: 761367744.0000 - accuracy: 0.0000e+00\n","Epoch 284/300\n","347/347 [==============================] - 1s 2ms/step - loss: 756871424.0000 - accuracy: 0.0000e+00\n","Epoch 285/300\n","347/347 [==============================] - 1s 2ms/step - loss: 751517632.0000 - accuracy: 0.0000e+00\n","Epoch 286/300\n","347/347 [==============================] - 1s 2ms/step - loss: 745078208.0000 - accuracy: 0.0000e+00\n","Epoch 287/300\n","347/347 [==============================] - 1s 2ms/step - loss: 740592960.0000 - accuracy: 0.0000e+00\n","Epoch 288/300\n","347/347 [==============================] - 1s 2ms/step - loss: 736777024.0000 - accuracy: 0.0000e+00\n","Epoch 289/300\n","347/347 [==============================] - 1s 2ms/step - loss: 725075200.0000 - accuracy: 0.0000e+00\n","Epoch 290/300\n","347/347 [==============================] - 1s 2ms/step - loss: 724444032.0000 - accuracy: 0.0000e+00\n","Epoch 291/300\n","347/347 [==============================] - 1s 2ms/step - loss: 714681728.0000 - accuracy: 0.0000e+00\n","Epoch 292/300\n","347/347 [==============================] - 1s 2ms/step - loss: 712805760.0000 - accuracy: 0.0000e+00\n","Epoch 293/300\n","347/347 [==============================] - 1s 2ms/step - loss: 713800768.0000 - accuracy: 0.0000e+00\n","Epoch 294/300\n","347/347 [==============================] - 1s 2ms/step - loss: 703443712.0000 - accuracy: 0.0000e+00\n","Epoch 295/300\n","347/347 [==============================] - 1s 2ms/step - loss: 694769600.0000 - accuracy: 0.0000e+00\n","Epoch 296/300\n","347/347 [==============================] - 1s 2ms/step - loss: 694378304.0000 - accuracy: 0.0000e+00\n","Epoch 297/300\n","347/347 [==============================] - 1s 2ms/step - loss: 683662784.0000 - accuracy: 0.0000e+00\n","Epoch 298/300\n","347/347 [==============================] - 1s 2ms/step - loss: 677515712.0000 - accuracy: 0.0000e+00\n","Epoch 299/300\n","347/347 [==============================] - 1s 2ms/step - loss: 675654528.0000 - accuracy: 0.0000e+00\n","Epoch 300/300\n","347/347 [==============================] - 1s 2ms/step - loss: 669206976.0000 - accuracy: 0.0000e+00\n","Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_8 (Dense)             (None, 30)                930       \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 30)               120       \n"," hNormalization)                                                 \n","                                                                 \n"," dense_9 (Dense)             (None, 1)                 31        \n","                                                                 \n","=================================================================\n","Total params: 1,081\n","Trainable params: 1,021\n","Non-trainable params: 60\n","_________________________________________________________________\n","87/87 [==============================] - 0s 1ms/step\n","[[11164.446 ]\n"," [ 4870.155 ]\n"," [ 5877.0903]\n"," ...\n"," [ 6852.3735]\n"," [ 3765.5078]\n"," [ 6220.589 ]]\n"]}],"source":["h_model.fit(X_train, y_train, epochs=300)\n","h_model.summary()\n","print(h_model.predict(X_test))"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameter Tuning \n","Some experiments and parameter hypertuning that were done to try and get better results were:\n","* Making the model Deeper by adding another layer, 2 layers instead of 1\n","* Making the model wider by adding more neurons, adding up to 128 in the first layer\n","* Changing the Adam optimizer to rmsprop. Increasing and Decreasing the Adam optimizer\n","* Increasing the training time from 300 to 600 epoch\n","\n","All of these experiments did not lead to better results. These experiments were all also done using the preprocessed data and still do not give better results. So the baseline model with preprocessed data was chosen to be the Main Model. "]},{"cell_type":"markdown","metadata":{},"source":["### Model 1"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","330/330 [==============================] - 2s 3ms/step - loss: 1858772608.0000 - val_loss: 1816252160.0000\n","Epoch 2/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1853295232.0000 - val_loss: 1808162304.0000\n","Epoch 3/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1844590080.0000 - val_loss: 1797342976.0000\n","Epoch 4/100\n","330/330 [==============================] - 1s 3ms/step - loss: 1832789504.0000 - val_loss: 1782532224.0000\n","Epoch 5/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1818104704.0000 - val_loss: 1765772672.0000\n","Epoch 6/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1800676608.0000 - val_loss: 1745784576.0000\n","Epoch 7/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1780979584.0000 - val_loss: 1728213632.0000\n","Epoch 8/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1759193600.0000 - val_loss: 1705379072.0000\n","Epoch 9/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1735557376.0000 - val_loss: 1680325504.0000\n","Epoch 10/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1709962496.0000 - val_loss: 1651264896.0000\n","Epoch 11/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1682624128.0000 - val_loss: 1614701056.0000\n","Epoch 12/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1653867008.0000 - val_loss: 1596627968.0000\n","Epoch 13/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1624132864.0000 - val_loss: 1559810048.0000\n","Epoch 14/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1593046016.0000 - val_loss: 1547221504.0000\n","Epoch 15/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1560689792.0000 - val_loss: 1496856064.0000\n","Epoch 16/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1525595520.0000 - val_loss: 1467002112.0000\n","Epoch 17/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1492573312.0000 - val_loss: 1421669376.0000\n","Epoch 18/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1456240384.0000 - val_loss: 1386287744.0000\n","Epoch 19/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1419079552.0000 - val_loss: 1345402240.0000\n","Epoch 20/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1382887424.0000 - val_loss: 1322311040.0000\n","Epoch 21/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1344349568.0000 - val_loss: 1258074240.0000\n","Epoch 22/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1305913216.0000 - val_loss: 1236315392.0000\n","Epoch 23/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1267425024.0000 - val_loss: 1182491776.0000\n","Epoch 24/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1227995648.0000 - val_loss: 1151297152.0000\n","Epoch 25/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1188607360.0000 - val_loss: 1099156864.0000\n","Epoch 26/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1146229120.0000 - val_loss: 1065163072.0000\n","Epoch 27/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1105958912.0000 - val_loss: 1020336384.0000\n","Epoch 28/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1065859072.0000 - val_loss: 968227008.0000\n","Epoch 29/100\n","330/330 [==============================] - 1s 2ms/step - loss: 1024514240.0000 - val_loss: 923425280.0000\n","Epoch 30/100\n","330/330 [==============================] - 1s 2ms/step - loss: 984350272.0000 - val_loss: 884583424.0000\n","Epoch 31/100\n","330/330 [==============================] - 1s 2ms/step - loss: 943092096.0000 - val_loss: 860852352.0000\n","Epoch 32/100\n","330/330 [==============================] - 1s 2ms/step - loss: 903433344.0000 - val_loss: 821012096.0000\n","Epoch 33/100\n","330/330 [==============================] - 1s 2ms/step - loss: 864228288.0000 - val_loss: 763195968.0000\n","Epoch 34/100\n","330/330 [==============================] - 1s 2ms/step - loss: 825990592.0000 - val_loss: 729410368.0000\n","Epoch 35/100\n","330/330 [==============================] - 0s 1ms/step - loss: 783296960.0000 - val_loss: 693774784.0000\n","Epoch 36/100\n","330/330 [==============================] - 1s 2ms/step - loss: 750115520.0000 - val_loss: 670344128.0000\n","Epoch 37/100\n","330/330 [==============================] - 1s 2ms/step - loss: 708368768.0000 - val_loss: 613359552.0000\n","Epoch 38/100\n","330/330 [==============================] - 1s 2ms/step - loss: 674746048.0000 - val_loss: 587094592.0000\n","Epoch 39/100\n","330/330 [==============================] - 1s 2ms/step - loss: 634956992.0000 - val_loss: 547764544.0000\n","Epoch 40/100\n","330/330 [==============================] - 1s 2ms/step - loss: 600059200.0000 - val_loss: 503766624.0000\n","Epoch 41/100\n","330/330 [==============================] - 1s 3ms/step - loss: 564573120.0000 - val_loss: 489768736.0000\n","Epoch 42/100\n","330/330 [==============================] - 1s 2ms/step - loss: 526318016.0000 - val_loss: 432571136.0000\n","Epoch 43/100\n","330/330 [==============================] - 1s 2ms/step - loss: 494023744.0000 - val_loss: 408578176.0000\n","Epoch 44/100\n","330/330 [==============================] - 1s 2ms/step - loss: 463494432.0000 - val_loss: 379656320.0000\n","Epoch 45/100\n","330/330 [==============================] - 1s 2ms/step - loss: 435526048.0000 - val_loss: 335450528.0000\n","Epoch 46/100\n","330/330 [==============================] - 1s 2ms/step - loss: 405888896.0000 - val_loss: 319201280.0000\n","Epoch 47/100\n","330/330 [==============================] - 1s 2ms/step - loss: 376234848.0000 - val_loss: 272322560.0000\n","Epoch 48/100\n","330/330 [==============================] - 1s 2ms/step - loss: 353999616.0000 - val_loss: 259077888.0000\n","Epoch 49/100\n","330/330 [==============================] - 1s 2ms/step - loss: 320615104.0000 - val_loss: 248021904.0000\n","Epoch 50/100\n","330/330 [==============================] - 1s 3ms/step - loss: 292102752.0000 - val_loss: 207920112.0000\n","Epoch 51/100\n","330/330 [==============================] - 1s 2ms/step - loss: 277327104.0000 - val_loss: 200085168.0000\n","Epoch 52/100\n","330/330 [==============================] - 1s 2ms/step - loss: 255884576.0000 - val_loss: 166237744.0000\n","Epoch 53/100\n","330/330 [==============================] - 1s 2ms/step - loss: 245156240.0000 - val_loss: 145406720.0000\n","Epoch 54/100\n","330/330 [==============================] - 1s 2ms/step - loss: 221605616.0000 - val_loss: 133920088.0000\n","Epoch 55/100\n","330/330 [==============================] - 1s 2ms/step - loss: 209674416.0000 - val_loss: 110223408.0000\n","Epoch 56/100\n","330/330 [==============================] - 1s 2ms/step - loss: 188057328.0000 - val_loss: 103955312.0000\n","Epoch 57/100\n","330/330 [==============================] - 1s 2ms/step - loss: 181665408.0000 - val_loss: 94161184.0000\n","Epoch 58/100\n","330/330 [==============================] - 1s 2ms/step - loss: 168730720.0000 - val_loss: 77810536.0000\n","Epoch 59/100\n","330/330 [==============================] - 1s 2ms/step - loss: 157068128.0000 - val_loss: 62547692.0000\n","Epoch 60/100\n","330/330 [==============================] - 1s 3ms/step - loss: 141407040.0000 - val_loss: 58999092.0000\n","Epoch 61/100\n","330/330 [==============================] - 1s 2ms/step - loss: 144367328.0000 - val_loss: 47606540.0000\n","Epoch 62/100\n","330/330 [==============================] - 1s 3ms/step - loss: 125138032.0000 - val_loss: 54258380.0000\n","Epoch 63/100\n","330/330 [==============================] - 1s 3ms/step - loss: 122069224.0000 - val_loss: 31144988.0000\n","Epoch 64/100\n","330/330 [==============================] - 1s 2ms/step - loss: 114943552.0000 - val_loss: 26709356.0000\n","Epoch 65/100\n","330/330 [==============================] - 1s 2ms/step - loss: 109120456.0000 - val_loss: 18291636.0000\n","Epoch 66/100\n","330/330 [==============================] - 1s 2ms/step - loss: 108232008.0000 - val_loss: 16546381.0000\n","Epoch 67/100\n","330/330 [==============================] - 1s 2ms/step - loss: 107019400.0000 - val_loss: 13382447.0000\n","Epoch 68/100\n","330/330 [==============================] - 1s 2ms/step - loss: 103874824.0000 - val_loss: 25915186.0000\n","Epoch 69/100\n","330/330 [==============================] - 1s 3ms/step - loss: 103844888.0000 - val_loss: 22766684.0000\n","Epoch 70/100\n","330/330 [==============================] - 1s 2ms/step - loss: 98704480.0000 - val_loss: 52446844.0000\n","Epoch 71/100\n","330/330 [==============================] - 1s 2ms/step - loss: 94552088.0000 - val_loss: 9072094.0000\n","Epoch 72/100\n","330/330 [==============================] - 1s 2ms/step - loss: 98961656.0000 - val_loss: 31937446.0000\n","Epoch 73/100\n","330/330 [==============================] - 1s 2ms/step - loss: 83084024.0000 - val_loss: 14096226.0000\n","Epoch 74/100\n","330/330 [==============================] - 1s 2ms/step - loss: 80896368.0000 - val_loss: 32401688.0000\n","Epoch 75/100\n","330/330 [==============================] - 1s 2ms/step - loss: 72503056.0000 - val_loss: 5992209.5000\n","Epoch 76/100\n","330/330 [==============================] - 1s 2ms/step - loss: 76649344.0000 - val_loss: 3418023.7500\n","Epoch 77/100\n","330/330 [==============================] - 1s 2ms/step - loss: 73189456.0000 - val_loss: 15886681.0000\n","Epoch 78/100\n","330/330 [==============================] - 1s 3ms/step - loss: 62826320.0000 - val_loss: 11579152.0000\n","Epoch 79/100\n","330/330 [==============================] - 1s 2ms/step - loss: 63774280.0000 - val_loss: 10811184.0000\n","Epoch 80/100\n","330/330 [==============================] - 1s 2ms/step - loss: 63899924.0000 - val_loss: 17844282.0000\n","Epoch 81/100\n","330/330 [==============================] - 1s 2ms/step - loss: 59832652.0000 - val_loss: 3192439.5000\n","Epoch 82/100\n","330/330 [==============================] - 1s 2ms/step - loss: 62831516.0000 - val_loss: 2086490.3750\n","Epoch 83/100\n","330/330 [==============================] - 1s 2ms/step - loss: 53308148.0000 - val_loss: 2847531.2500\n","Epoch 84/100\n","330/330 [==============================] - 1s 2ms/step - loss: 57998056.0000 - val_loss: 26063376.0000\n","Epoch 85/100\n","330/330 [==============================] - 1s 2ms/step - loss: 54251268.0000 - val_loss: 13823188.0000\n","Epoch 86/100\n","330/330 [==============================] - 1s 2ms/step - loss: 58527572.0000 - val_loss: 6478324.5000\n","Epoch 87/100\n","330/330 [==============================] - 1s 2ms/step - loss: 59340636.0000 - val_loss: 6497807.0000\n","Epoch 88/100\n","330/330 [==============================] - 1s 2ms/step - loss: 56610988.0000 - val_loss: 26038754.0000\n","Epoch 89/100\n","330/330 [==============================] - 1s 2ms/step - loss: 56893468.0000 - val_loss: 13397549.0000\n","Epoch 90/100\n","330/330 [==============================] - 1s 2ms/step - loss: 52288736.0000 - val_loss: 1816360.2500\n","Epoch 91/100\n","330/330 [==============================] - 1s 2ms/step - loss: 57813960.0000 - val_loss: 9854271.0000\n","Epoch 92/100\n","330/330 [==============================] - 1s 2ms/step - loss: 50409080.0000 - val_loss: 4918073.5000\n","Epoch 93/100\n","330/330 [==============================] - 1s 2ms/step - loss: 54908536.0000 - val_loss: 9961040.0000\n","Epoch 94/100\n","330/330 [==============================] - 0s 1ms/step - loss: 55883144.0000 - val_loss: 5728902.0000\n","Epoch 95/100\n","330/330 [==============================] - 1s 2ms/step - loss: 55053852.0000 - val_loss: 1137091.6250\n","Epoch 96/100\n","330/330 [==============================] - 1s 2ms/step - loss: 51430344.0000 - val_loss: 7386811.0000\n","Epoch 97/100\n","330/330 [==============================] - 1s 2ms/step - loss: 47178648.0000 - val_loss: 3375439.5000\n","Epoch 98/100\n","330/330 [==============================] - 1s 2ms/step - loss: 51359516.0000 - val_loss: 3717195.7500\n","Epoch 99/100\n","330/330 [==============================] - 1s 2ms/step - loss: 45787164.0000 - val_loss: 4590723.0000\n","Epoch 100/100\n","330/330 [==============================] - 1s 2ms/step - loss: 47490024.0000 - val_loss: 1555543.1250\n","Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_10 (Dense)            (None, 64)                1984      \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 64)               256       \n"," hNormalization)                                                 \n","                                                                 \n"," dense_11 (Dense)            (None, 64)                4160      \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 64)               256       \n"," hNormalization)                                                 \n","                                                                 \n"," dense_12 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 6,721\n","Trainable params: 6,465\n","Non-trainable params: 256\n","_________________________________________________________________\n","87/87 [==============================] - 0s 1ms/step\n","[[25959.74  ]\n"," [10830.158 ]\n"," [ 7228.858 ]\n"," ...\n"," [13399.154 ]\n"," [ 3186.8127]\n"," [13193.001 ]]\n"]}],"source":["# Hyperparameter Tuning\n","# importing matplotlib module \n","import matplotlib.pyplot as plt\n","\n","X_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=1)\n","\n","#build model 1\n","model = keras.models.Sequential([\n","    keras.layers.Dense(64, activation=\"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(64, activation=\"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(1)\n","])\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","\n","#fit model\n","history = model.fit(X_train, y_train, epochs= 100, validation_data=(x_val, y_val))\n","\n","model.summary()\n","\n","\n","#evaluate the model\n","print(model.predict(X_test))"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[25005.]\n"," [ 9664.]\n"," [ 6053.]\n"," ...\n"," [12549.]\n"," [ 1204.]\n"," [13000.]]\n"]}],"source":["print(y_test)"]},{"cell_type":"markdown","metadata":{},"source":["### Model 2"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1868411008.0000 - val_loss: 1676204032.0000\n","Epoch 2/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1863481344.0000 - val_loss: 1669443072.0000\n","Epoch 3/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1855659648.0000 - val_loss: 1659610240.0000\n","Epoch 4/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1845029248.0000 - val_loss: 1648315776.0000\n","Epoch 5/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1831660416.0000 - val_loss: 1635614592.0000\n","Epoch 6/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1815784704.0000 - val_loss: 1619479296.0000\n","Epoch 7/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1798028544.0000 - val_loss: 1604740736.0000\n","Epoch 8/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1777937280.0000 - val_loss: 1583490048.0000\n","Epoch 9/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1756371456.0000 - val_loss: 1556751232.0000\n","Epoch 10/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1732975744.0000 - val_loss: 1534501504.0000\n","Epoch 11/100\n","313/313 [==============================] - 1s 3ms/step - loss: 1707990656.0000 - val_loss: 1515441024.0000\n","Epoch 12/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1680791424.0000 - val_loss: 1491555456.0000\n","Epoch 13/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1652935040.0000 - val_loss: 1465733632.0000\n","Epoch 14/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1624341248.0000 - val_loss: 1430445056.0000\n","Epoch 15/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1593791872.0000 - val_loss: 1406548736.0000\n","Epoch 16/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1562708864.0000 - val_loss: 1378022912.0000\n","Epoch 17/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1531042560.0000 - val_loss: 1336262656.0000\n","Epoch 18/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1498177792.0000 - val_loss: 1300054528.0000\n","Epoch 19/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1463995520.0000 - val_loss: 1286531072.0000\n","Epoch 20/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1429944576.0000 - val_loss: 1237932672.0000\n","Epoch 21/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1393226880.0000 - val_loss: 1215921280.0000\n","Epoch 22/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1355941760.0000 - val_loss: 1179836160.0000\n","Epoch 23/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1319766016.0000 - val_loss: 1152881408.0000\n","Epoch 24/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1283348992.0000 - val_loss: 1108305664.0000\n","Epoch 25/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1244496768.0000 - val_loss: 1064119808.0000\n","Epoch 26/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1206401664.0000 - val_loss: 1051538752.0000\n","Epoch 27/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1171150336.0000 - val_loss: 1010939008.0000\n","Epoch 28/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1130776960.0000 - val_loss: 990548160.0000\n","Epoch 29/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1094143104.0000 - val_loss: 941484800.0000\n","Epoch 30/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1057620160.0000 - val_loss: 895097600.0000\n","Epoch 31/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1018520000.0000 - val_loss: 844265216.0000\n","Epoch 32/100\n","313/313 [==============================] - 1s 2ms/step - loss: 977393664.0000 - val_loss: 822012352.0000\n","Epoch 33/100\n","313/313 [==============================] - 1s 2ms/step - loss: 935766400.0000 - val_loss: 772307200.0000\n","Epoch 34/100\n","313/313 [==============================] - 1s 2ms/step - loss: 902426624.0000 - val_loss: 804160704.0000\n","Epoch 35/100\n","313/313 [==============================] - 1s 2ms/step - loss: 862743616.0000 - val_loss: 703765568.0000\n","Epoch 36/100\n","313/313 [==============================] - 1s 2ms/step - loss: 822338368.0000 - val_loss: 674860032.0000\n","Epoch 37/100\n","313/313 [==============================] - 1s 2ms/step - loss: 785742912.0000 - val_loss: 634462272.0000\n","Epoch 38/100\n","313/313 [==============================] - 1s 2ms/step - loss: 748197824.0000 - val_loss: 605274432.0000\n","Epoch 39/100\n","313/313 [==============================] - 1s 2ms/step - loss: 712546688.0000 - val_loss: 594616320.0000\n","Epoch 40/100\n","313/313 [==============================] - 1s 2ms/step - loss: 677414848.0000 - val_loss: 556793856.0000\n","Epoch 41/100\n","313/313 [==============================] - 1s 2ms/step - loss: 641948608.0000 - val_loss: 496995712.0000\n","Epoch 42/100\n","313/313 [==============================] - 1s 2ms/step - loss: 607608512.0000 - val_loss: 487709248.0000\n","Epoch 43/100\n","313/313 [==============================] - 1s 2ms/step - loss: 575270208.0000 - val_loss: 457137792.0000\n","Epoch 44/100\n","313/313 [==============================] - 1s 3ms/step - loss: 537067072.0000 - val_loss: 413739776.0000\n","Epoch 45/100\n","313/313 [==============================] - 1s 2ms/step - loss: 513920832.0000 - val_loss: 376242304.0000\n","Epoch 46/100\n","313/313 [==============================] - 1s 2ms/step - loss: 472165472.0000 - val_loss: 330222176.0000\n","Epoch 47/100\n","313/313 [==============================] - 1s 2ms/step - loss: 442633440.0000 - val_loss: 356395520.0000\n","Epoch 48/100\n","313/313 [==============================] - 1s 2ms/step - loss: 422122464.0000 - val_loss: 318745696.0000\n","Epoch 49/100\n","313/313 [==============================] - 1s 2ms/step - loss: 390506720.0000 - val_loss: 284047680.0000\n","Epoch 50/100\n","313/313 [==============================] - 1s 2ms/step - loss: 369430528.0000 - val_loss: 303069376.0000\n","Epoch 51/100\n","313/313 [==============================] - 1s 2ms/step - loss: 346684736.0000 - val_loss: 243382464.0000\n","Epoch 52/100\n","313/313 [==============================] - 1s 2ms/step - loss: 328002656.0000 - val_loss: 226911360.0000\n","Epoch 53/100\n","313/313 [==============================] - 1s 2ms/step - loss: 292134400.0000 - val_loss: 179825072.0000\n","Epoch 54/100\n","313/313 [==============================] - 1s 2ms/step - loss: 270612096.0000 - val_loss: 171920352.0000\n","Epoch 55/100\n","313/313 [==============================] - 1s 2ms/step - loss: 249077168.0000 - val_loss: 158200368.0000\n","Epoch 56/100\n","313/313 [==============================] - 1s 2ms/step - loss: 235751712.0000 - val_loss: 135568096.0000\n","Epoch 57/100\n","313/313 [==============================] - 1s 2ms/step - loss: 228416304.0000 - val_loss: 122135432.0000\n","Epoch 58/100\n","313/313 [==============================] - 1s 2ms/step - loss: 208966736.0000 - val_loss: 105091184.0000\n","Epoch 59/100\n","313/313 [==============================] - 1s 2ms/step - loss: 197402528.0000 - val_loss: 87087800.0000\n","Epoch 60/100\n","313/313 [==============================] - 1s 2ms/step - loss: 171157728.0000 - val_loss: 80208808.0000\n","Epoch 61/100\n","313/313 [==============================] - 1s 2ms/step - loss: 171174848.0000 - val_loss: 63803256.0000\n","Epoch 62/100\n","313/313 [==============================] - 1s 2ms/step - loss: 154375808.0000 - val_loss: 66397464.0000\n","Epoch 63/100\n","313/313 [==============================] - 1s 2ms/step - loss: 152387360.0000 - val_loss: 58695776.0000\n","Epoch 64/100\n","313/313 [==============================] - 1s 2ms/step - loss: 140772016.0000 - val_loss: 49735636.0000\n","Epoch 65/100\n","313/313 [==============================] - 1s 2ms/step - loss: 137163008.0000 - val_loss: 35936272.0000\n","Epoch 66/100\n","313/313 [==============================] - 1s 2ms/step - loss: 127976472.0000 - val_loss: 39309084.0000\n","Epoch 67/100\n","313/313 [==============================] - 1s 2ms/step - loss: 119434576.0000 - val_loss: 35819884.0000\n","Epoch 68/100\n","313/313 [==============================] - 1s 2ms/step - loss: 109324568.0000 - val_loss: 30773884.0000\n","Epoch 69/100\n","313/313 [==============================] - 1s 2ms/step - loss: 112892248.0000 - val_loss: 18704768.0000\n","Epoch 70/100\n","313/313 [==============================] - 1s 2ms/step - loss: 95902872.0000 - val_loss: 23690016.0000\n","Epoch 71/100\n","313/313 [==============================] - 1s 2ms/step - loss: 107217568.0000 - val_loss: 17332692.0000\n","Epoch 72/100\n","313/313 [==============================] - 1s 2ms/step - loss: 96072664.0000 - val_loss: 21136718.0000\n","Epoch 73/100\n","313/313 [==============================] - 1s 2ms/step - loss: 101687128.0000 - val_loss: 11705552.0000\n","Epoch 74/100\n","313/313 [==============================] - 1s 2ms/step - loss: 95972720.0000 - val_loss: 16511882.0000\n","Epoch 75/100\n","313/313 [==============================] - 1s 2ms/step - loss: 90142104.0000 - val_loss: 27457882.0000\n","Epoch 76/100\n","313/313 [==============================] - 1s 3ms/step - loss: 90115896.0000 - val_loss: 18488968.0000\n","Epoch 77/100\n","313/313 [==============================] - 1s 3ms/step - loss: 80270800.0000 - val_loss: 29191004.0000\n","Epoch 78/100\n","313/313 [==============================] - 1s 3ms/step - loss: 79330288.0000 - val_loss: 4111139.5000\n","Epoch 79/100\n","313/313 [==============================] - 1s 2ms/step - loss: 78413144.0000 - val_loss: 6729607.0000\n","Epoch 80/100\n","313/313 [==============================] - 1s 2ms/step - loss: 73347936.0000 - val_loss: 11324421.0000\n","Epoch 81/100\n","313/313 [==============================] - 1s 2ms/step - loss: 74616360.0000 - val_loss: 7437172.5000\n","Epoch 82/100\n","313/313 [==============================] - 0s 1ms/step - loss: 75051256.0000 - val_loss: 5696856.0000\n","Epoch 83/100\n","313/313 [==============================] - 0s 1ms/step - loss: 66254932.0000 - val_loss: 11861423.0000\n","Epoch 84/100\n","313/313 [==============================] - 1s 2ms/step - loss: 75337136.0000 - val_loss: 13330877.0000\n","Epoch 85/100\n","313/313 [==============================] - 1s 2ms/step - loss: 77263088.0000 - val_loss: 5670121.0000\n","Epoch 86/100\n","313/313 [==============================] - 1s 2ms/step - loss: 57586104.0000 - val_loss: 9706608.0000\n","Epoch 87/100\n","313/313 [==============================] - 1s 2ms/step - loss: 59448000.0000 - val_loss: 9473910.0000\n","Epoch 88/100\n","313/313 [==============================] - 1s 2ms/step - loss: 58425640.0000 - val_loss: 4220147.0000\n","Epoch 89/100\n","313/313 [==============================] - 1s 3ms/step - loss: 56349976.0000 - val_loss: 2843493.2500\n","Epoch 90/100\n","313/313 [==============================] - 1s 3ms/step - loss: 54711756.0000 - val_loss: 6486095.5000\n","Epoch 91/100\n","313/313 [==============================] - 1s 2ms/step - loss: 58740708.0000 - val_loss: 2161140.5000\n","Epoch 92/100\n","313/313 [==============================] - 1s 2ms/step - loss: 59471804.0000 - val_loss: 17137344.0000\n","Epoch 93/100\n","313/313 [==============================] - 0s 1ms/step - loss: 51569192.0000 - val_loss: 2411958.2500\n","Epoch 94/100\n","313/313 [==============================] - 0s 1ms/step - loss: 61141776.0000 - val_loss: 3134325.7500\n","Epoch 95/100\n","313/313 [==============================] - 0s 1ms/step - loss: 56640560.0000 - val_loss: 5228112.0000\n","Epoch 96/100\n","313/313 [==============================] - 0s 1ms/step - loss: 52180232.0000 - val_loss: 5796454.0000\n","Epoch 97/100\n","313/313 [==============================] - 0s 1ms/step - loss: 50895716.0000 - val_loss: 2236250.2500\n","Epoch 98/100\n","313/313 [==============================] - 0s 1ms/step - loss: 44630008.0000 - val_loss: 12580544.0000\n","Epoch 99/100\n","313/313 [==============================] - 0s 1ms/step - loss: 46627180.0000 - val_loss: 8498881.0000\n","Epoch 100/100\n","313/313 [==============================] - 0s 1ms/step - loss: 52996428.0000 - val_loss: 4728351.5000\n","Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_13 (Dense)            (None, 128)               3968      \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 128)              512       \n"," hNormalization)                                                 \n","                                                                 \n"," dense_14 (Dense)            (None, 64)                8256      \n","                                                                 \n"," batch_normalization_8 (Batc  (None, 64)               256       \n"," hNormalization)                                                 \n","                                                                 \n"," dense_15 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 13,057\n","Trainable params: 12,673\n","Non-trainable params: 384\n","_________________________________________________________________\n","87/87 [==============================] - 0s 895us/step\n","[[27644.666]\n"," [11052.51 ]\n"," [ 8301.465]\n"," ...\n"," [14710.396]\n"," [ 3106.49 ]\n"," [14769.193]]\n"]}],"source":["X_train, x_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=1)\n","\n","#build model 2\n","model = keras.models.Sequential([\n","    keras.layers.Dense(128, activation=\"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(64, activation=\"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(1)\n","])\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","\n","#fit model\n","history = model.fit(X_train, y_train, epochs= 100, validation_data=(x_val, y_val))\n","\n","model.summary()\n","\n","#evaluate the model\n","print(model.predict(X_test))"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[25005.]\n"," [ 9664.]\n"," [ 6053.]\n"," ...\n"," [12549.]\n"," [ 1204.]\n"," [13000.]]\n"]}],"source":["print(y_test)"]},{"cell_type":"markdown","metadata":{},"source":["### Model 3"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1868375552.0000 - val_loss: 1675928960.0000\n","Epoch 2/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1863719424.0000 - val_loss: 1668081024.0000\n","Epoch 3/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1856113408.0000 - val_loss: 1658908800.0000\n","Epoch 4/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1845645440.0000 - val_loss: 1648431616.0000\n","Epoch 5/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1832390144.0000 - val_loss: 1631388544.0000\n","Epoch 6/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1816586496.0000 - val_loss: 1618997120.0000\n","Epoch 7/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1798952576.0000 - val_loss: 1600019584.0000\n","Epoch 8/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1778950144.0000 - val_loss: 1582179712.0000\n","Epoch 9/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1757512832.0000 - val_loss: 1571114240.0000\n","Epoch 10/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1734199296.0000 - val_loss: 1537880832.0000\n","Epoch 11/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1709291392.0000 - val_loss: 1509935872.0000\n","Epoch 12/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1682109952.0000 - val_loss: 1488758656.0000\n","Epoch 13/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1654379648.0000 - val_loss: 1470966144.0000\n","Epoch 14/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1625842816.0000 - val_loss: 1432250624.0000\n","Epoch 15/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1595433472.0000 - val_loss: 1426681728.0000\n","Epoch 16/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1564382976.0000 - val_loss: 1365336064.0000\n","Epoch 17/100\n","313/313 [==============================] - 0s 2ms/step - loss: 1532804096.0000 - val_loss: 1330793344.0000\n","Epoch 18/100\n","313/313 [==============================] - 0s 2ms/step - loss: 1500027264.0000 - val_loss: 1308429184.0000\n","Epoch 19/100\n","313/313 [==============================] - 0s 2ms/step - loss: 1465909376.0000 - val_loss: 1286889600.0000\n","Epoch 20/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1431966592.0000 - val_loss: 1239858816.0000\n","Epoch 21/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1395446016.0000 - val_loss: 1226914944.0000\n","Epoch 22/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1358161536.0000 - val_loss: 1167441920.0000\n","Epoch 23/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1322035072.0000 - val_loss: 1170143360.0000\n","Epoch 24/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1285790720.0000 - val_loss: 1118662784.0000\n","Epoch 25/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1246954624.0000 - val_loss: 1070658176.0000\n","Epoch 26/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1208904064.0000 - val_loss: 1079543168.0000\n","Epoch 27/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1173788032.0000 - val_loss: 1043041792.0000\n","Epoch 28/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1133459712.0000 - val_loss: 970346432.0000\n","Epoch 29/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1096975104.0000 - val_loss: 940902976.0000\n","Epoch 30/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1060444480.0000 - val_loss: 920098688.0000\n","Epoch 31/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1021401408.0000 - val_loss: 861283968.0000\n","Epoch 32/100\n","313/313 [==============================] - 1s 2ms/step - loss: 980336448.0000 - val_loss: 809094784.0000\n","Epoch 33/100\n","313/313 [==============================] - 1s 2ms/step - loss: 938739392.0000 - val_loss: 808807424.0000\n","Epoch 34/100\n","313/313 [==============================] - 1s 2ms/step - loss: 905394112.0000 - val_loss: 745269696.0000\n","Epoch 35/100\n","313/313 [==============================] - 0s 2ms/step - loss: 865787328.0000 - val_loss: 716718016.0000\n","Epoch 36/100\n","313/313 [==============================] - 1s 2ms/step - loss: 825498624.0000 - val_loss: 699934400.0000\n","Epoch 37/100\n","313/313 [==============================] - 1s 2ms/step - loss: 788933248.0000 - val_loss: 651257856.0000\n","Epoch 38/100\n","313/313 [==============================] - 0s 1ms/step - loss: 751354432.0000 - val_loss: 627509248.0000\n","Epoch 39/100\n","313/313 [==============================] - 0s 1ms/step - loss: 715817664.0000 - val_loss: 561564096.0000\n","Epoch 40/100\n","313/313 [==============================] - 0s 1ms/step - loss: 680662720.0000 - val_loss: 566137664.0000\n","Epoch 41/100\n","313/313 [==============================] - 1s 2ms/step - loss: 645213824.0000 - val_loss: 524116032.0000\n","Epoch 42/100\n","313/313 [==============================] - 1s 2ms/step - loss: 610839872.0000 - val_loss: 489097120.0000\n","Epoch 43/100\n","313/313 [==============================] - 0s 1ms/step - loss: 578493632.0000 - val_loss: 472465504.0000\n","Epoch 44/100\n","313/313 [==============================] - 1s 2ms/step - loss: 540210304.0000 - val_loss: 468140064.0000\n","Epoch 45/100\n","313/313 [==============================] - 1s 2ms/step - loss: 517129344.0000 - val_loss: 408074080.0000\n","Epoch 46/100\n","313/313 [==============================] - 1s 2ms/step - loss: 475404704.0000 - val_loss: 384609184.0000\n","Epoch 47/100\n","313/313 [==============================] - 1s 2ms/step - loss: 445667200.0000 - val_loss: 359823424.0000\n","Epoch 48/100\n","313/313 [==============================] - 1s 2ms/step - loss: 425228736.0000 - val_loss: 311020608.0000\n","Epoch 49/100\n","313/313 [==============================] - 1s 2ms/step - loss: 393768064.0000 - val_loss: 291552000.0000\n","Epoch 50/100\n","313/313 [==============================] - 0s 2ms/step - loss: 372585920.0000 - val_loss: 282394816.0000\n","Epoch 51/100\n","313/313 [==============================] - 0s 1ms/step - loss: 349796352.0000 - val_loss: 235074496.0000\n","Epoch 52/100\n","313/313 [==============================] - 1s 2ms/step - loss: 330875328.0000 - val_loss: 229153840.0000\n","Epoch 53/100\n","313/313 [==============================] - 0s 1ms/step - loss: 294926688.0000 - val_loss: 197925824.0000\n","Epoch 54/100\n","313/313 [==============================] - 0s 1ms/step - loss: 273394848.0000 - val_loss: 172314592.0000\n","Epoch 55/100\n","313/313 [==============================] - 0s 1ms/step - loss: 251767728.0000 - val_loss: 204813408.0000\n","Epoch 56/100\n","313/313 [==============================] - 0s 1ms/step - loss: 238440800.0000 - val_loss: 130905416.0000\n","Epoch 57/100\n","313/313 [==============================] - 0s 1ms/step - loss: 231011040.0000 - val_loss: 131541832.0000\n","Epoch 58/100\n","313/313 [==============================] - 0s 1ms/step - loss: 211364752.0000 - val_loss: 106689920.0000\n","Epoch 59/100\n","313/313 [==============================] - 0s 1ms/step - loss: 199670112.0000 - val_loss: 92208800.0000\n","Epoch 60/100\n","313/313 [==============================] - 1s 2ms/step - loss: 173379808.0000 - val_loss: 100863752.0000\n","Epoch 61/100\n","313/313 [==============================] - 1s 2ms/step - loss: 173001152.0000 - val_loss: 87497320.0000\n","Epoch 62/100\n","313/313 [==============================] - 0s 2ms/step - loss: 156257328.0000 - val_loss: 62140320.0000\n","Epoch 63/100\n","313/313 [==============================] - 0s 1ms/step - loss: 154149264.0000 - val_loss: 62168308.0000\n","Epoch 64/100\n","313/313 [==============================] - 1s 2ms/step - loss: 142414096.0000 - val_loss: 49386472.0000\n","Epoch 65/100\n","313/313 [==============================] - 0s 1ms/step - loss: 138220976.0000 - val_loss: 53863948.0000\n","Epoch 66/100\n","313/313 [==============================] - 0s 1ms/step - loss: 128212528.0000 - val_loss: 57424640.0000\n","Epoch 67/100\n","313/313 [==============================] - 0s 1ms/step - loss: 117761656.0000 - val_loss: 71988168.0000\n","Epoch 68/100\n","313/313 [==============================] - 0s 1ms/step - loss: 107048808.0000 - val_loss: 36879936.0000\n","Epoch 69/100\n","313/313 [==============================] - 0s 1ms/step - loss: 108826136.0000 - val_loss: 41271612.0000\n","Epoch 70/100\n","313/313 [==============================] - 0s 1ms/step - loss: 92820928.0000 - val_loss: 23432804.0000\n","Epoch 71/100\n","313/313 [==============================] - 0s 1ms/step - loss: 99176928.0000 - val_loss: 35205044.0000\n","Epoch 72/100\n","313/313 [==============================] - 0s 1ms/step - loss: 86499584.0000 - val_loss: 21730090.0000\n","Epoch 73/100\n","313/313 [==============================] - 0s 1ms/step - loss: 89141904.0000 - val_loss: 22183102.0000\n","Epoch 74/100\n","313/313 [==============================] - 0s 1ms/step - loss: 82281216.0000 - val_loss: 19385890.0000\n","Epoch 75/100\n","313/313 [==============================] - 0s 1ms/step - loss: 78037928.0000 - val_loss: 15683381.0000\n","Epoch 76/100\n","313/313 [==============================] - 0s 1ms/step - loss: 74608096.0000 - val_loss: 20972568.0000\n","Epoch 77/100\n","313/313 [==============================] - 1s 2ms/step - loss: 69544856.0000 - val_loss: 29420606.0000\n","Epoch 78/100\n","313/313 [==============================] - 0s 1ms/step - loss: 69426720.0000 - val_loss: 8572410.0000\n","Epoch 79/100\n","313/313 [==============================] - 0s 1ms/step - loss: 70084888.0000 - val_loss: 2378348.7500\n","Epoch 80/100\n","313/313 [==============================] - 0s 1ms/step - loss: 65389364.0000 - val_loss: 7141450.5000\n","Epoch 81/100\n","313/313 [==============================] - 0s 1ms/step - loss: 67224288.0000 - val_loss: 2578203.5000\n","Epoch 82/100\n","313/313 [==============================] - 0s 1ms/step - loss: 68601120.0000 - val_loss: 3931593.0000\n","Epoch 83/100\n","313/313 [==============================] - 0s 1ms/step - loss: 59904532.0000 - val_loss: 31601910.0000\n","Epoch 84/100\n","313/313 [==============================] - 0s 1ms/step - loss: 69419712.0000 - val_loss: 4338388.5000\n","Epoch 85/100\n","313/313 [==============================] - 0s 1ms/step - loss: 71118304.0000 - val_loss: 4093998.5000\n","Epoch 86/100\n","313/313 [==============================] - 0s 1ms/step - loss: 52621580.0000 - val_loss: 7887296.0000\n","Epoch 87/100\n","313/313 [==============================] - 0s 1ms/step - loss: 54156048.0000 - val_loss: 4601901.0000\n","Epoch 88/100\n","313/313 [==============================] - 0s 1ms/step - loss: 53836608.0000 - val_loss: 10272855.0000\n","Epoch 89/100\n","313/313 [==============================] - 0s 1ms/step - loss: 51934760.0000 - val_loss: 2906365.0000\n","Epoch 90/100\n","313/313 [==============================] - 0s 1ms/step - loss: 50591524.0000 - val_loss: 1839005.3750\n","Epoch 91/100\n","313/313 [==============================] - 0s 1ms/step - loss: 54571100.0000 - val_loss: 3014913.7500\n","Epoch 92/100\n","313/313 [==============================] - 0s 1ms/step - loss: 55739852.0000 - val_loss: 10753480.0000\n","Epoch 93/100\n","313/313 [==============================] - 0s 1ms/step - loss: 48152940.0000 - val_loss: 4306052.5000\n","Epoch 94/100\n","313/313 [==============================] - 0s 1ms/step - loss: 57319572.0000 - val_loss: 2893308.0000\n","Epoch 95/100\n","313/313 [==============================] - 0s 1ms/step - loss: 52854200.0000 - val_loss: 3761858.7500\n","Epoch 96/100\n","313/313 [==============================] - 0s 1ms/step - loss: 49099544.0000 - val_loss: 2772061.5000\n","Epoch 97/100\n","313/313 [==============================] - 0s 1ms/step - loss: 47958848.0000 - val_loss: 2856131.2500\n","Epoch 98/100\n","313/313 [==============================] - 0s 1ms/step - loss: 41845796.0000 - val_loss: 7496841.5000\n","Epoch 99/100\n","313/313 [==============================] - 0s 1ms/step - loss: 43538192.0000 - val_loss: 1796547.8750\n","Epoch 100/100\n","313/313 [==============================] - 0s 1ms/step - loss: 50170548.0000 - val_loss: 2617714.5000\n","Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_16 (Dense)            (None, 128)               3968      \n","                                                                 \n"," batch_normalization_9 (Batc  (None, 128)              512       \n"," hNormalization)                                                 \n","                                                                 \n"," dense_17 (Dense)            (None, 64)                8256      \n","                                                                 \n"," batch_normalization_10 (Bat  (None, 64)               256       \n"," chNormalization)                                                \n","                                                                 \n"," dense_18 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 13,057\n","Trainable params: 12,673\n","Non-trainable params: 384\n","_________________________________________________________________\n","87/87 [==============================] - 0s 767us/step\n","[[23850.557 ]\n"," [ 7726.307 ]\n"," [ 6662.197 ]\n"," ...\n"," [12164.416 ]\n"," [ 1576.4077]\n"," [12104.089 ]]\n"]}],"source":["#build model 3\n","model = keras.models.Sequential([\n","    keras.layers.Dense(128, activation=\"tanh\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(64, activation=\"tanh\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(1)\n","])\n","model.compile(loss='mean_squared_error', \n","              optimizer='adam')\n","\n","#fit model\n","history = model.fit(X_train, \n","                    y_train, \n","                    epochs= 100, \n","                    validation_data=(x_val, y_val))\n","\n","model.summary()\n","\n","#evaluate the model\n","print(model.predict(X_test))"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[25005.]\n"," [ 9664.]\n"," [ 6053.]\n"," ...\n"," [12549.]\n"," [ 1204.]\n"," [13000.]]\n"]}],"source":["print(y_test)"]},{"cell_type":"markdown","metadata":{},"source":["### Model 4"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","313/313 [==============================] - 2s 2ms/step - loss: 1868492288.0000 - val_loss: 1676323456.0000\n","Epoch 2/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1865149824.0000 - val_loss: 1672138880.0000\n","Epoch 3/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1860470016.0000 - val_loss: 1665696000.0000\n","Epoch 4/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1854497280.0000 - val_loss: 1659348352.0000\n","Epoch 5/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1846977408.0000 - val_loss: 1654097152.0000\n","Epoch 6/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1838067712.0000 - val_loss: 1644517760.0000\n","Epoch 7/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1828039424.0000 - val_loss: 1634961920.0000\n","Epoch 8/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1816367360.0000 - val_loss: 1622043520.0000\n","Epoch 9/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1803609728.0000 - val_loss: 1607476224.0000\n","Epoch 10/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1789434240.0000 - val_loss: 1594457984.0000\n","Epoch 11/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1773866752.0000 - val_loss: 1580114176.0000\n","Epoch 12/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1756586496.0000 - val_loss: 1565101824.0000\n","Epoch 13/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1738416128.0000 - val_loss: 1546712960.0000\n","Epoch 14/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1719232768.0000 - val_loss: 1520998400.0000\n","Epoch 15/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1698472064.0000 - val_loss: 1506328320.0000\n","Epoch 16/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1676817920.0000 - val_loss: 1484041088.0000\n","Epoch 17/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1654318208.0000 - val_loss: 1459505152.0000\n","Epoch 18/100\n","313/313 [==============================] - 0s 1ms/step - loss: 1630535936.0000 - val_loss: 1443861376.0000\n","Epoch 19/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1604972928.0000 - val_loss: 1422242176.0000\n","Epoch 20/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1579451776.0000 - val_loss: 1395738624.0000\n","Epoch 21/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1551288704.0000 - val_loss: 1361892224.0000\n","Epoch 22/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1522286208.0000 - val_loss: 1337635968.0000\n","Epoch 23/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1493520640.0000 - val_loss: 1321840128.0000\n","Epoch 24/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1463971328.0000 - val_loss: 1294931328.0000\n","Epoch 25/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1432325760.0000 - val_loss: 1258891776.0000\n","Epoch 26/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1400545664.0000 - val_loss: 1223396992.0000\n","Epoch 27/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1369965696.0000 - val_loss: 1201568896.0000\n","Epoch 28/100\n","313/313 [==============================] - 1s 3ms/step - loss: 1335413248.0000 - val_loss: 1179478144.0000\n","Epoch 29/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1303448704.0000 - val_loss: 1132059520.0000\n","Epoch 30/100\n","313/313 [==============================] - 1s 4ms/step - loss: 1270290048.0000 - val_loss: 1104525568.0000\n","Epoch 31/100\n","313/313 [==============================] - 1s 3ms/step - loss: 1235588352.0000 - val_loss: 1059564096.0000\n","Epoch 32/100\n","313/313 [==============================] - 1s 3ms/step - loss: 1198237568.0000 - val_loss: 1029849600.0000\n","Epoch 33/100\n","313/313 [==============================] - 1s 3ms/step - loss: 1160075264.0000 - val_loss: 993625792.0000\n","Epoch 34/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1127410048.0000 - val_loss: 976343296.0000\n","Epoch 35/100\n","313/313 [==============================] - 1s 2ms/step - loss: 1089621248.0000 - val_loss: 926958400.0000\n","Epoch 36/100\n","313/313 [==============================] - 1s 3ms/step - loss: 1050375232.0000 - val_loss: 889986496.0000\n","Epoch 37/100\n","313/313 [==============================] - 1s 3ms/step - loss: 1014338560.0000 - val_loss: 865510272.0000\n","Epoch 38/100\n","313/313 [==============================] - 1s 2ms/step - loss: 976399744.0000 - val_loss: 817041024.0000\n","Epoch 39/100\n","313/313 [==============================] - 1s 2ms/step - loss: 939172736.0000 - val_loss: 790817344.0000\n","Epoch 40/100\n","313/313 [==============================] - 1s 3ms/step - loss: 902478656.0000 - val_loss: 778166656.0000\n","Epoch 41/100\n","313/313 [==============================] - 1s 3ms/step - loss: 865347200.0000 - val_loss: 714919232.0000\n","Epoch 42/100\n","313/313 [==============================] - 1s 2ms/step - loss: 827793088.0000 - val_loss: 700390336.0000\n","Epoch 43/100\n","313/313 [==============================] - 1s 2ms/step - loss: 791975040.0000 - val_loss: 660595264.0000\n","Epoch 44/100\n","313/313 [==============================] - 0s 2ms/step - loss: 751065856.0000 - val_loss: 601625984.0000\n","Epoch 45/100\n","313/313 [==============================] - 1s 2ms/step - loss: 721707712.0000 - val_loss: 581911552.0000\n","Epoch 46/100\n","313/313 [==============================] - 1s 2ms/step - loss: 677123648.0000 - val_loss: 572739584.0000\n","Epoch 47/100\n","313/313 [==============================] - 1s 2ms/step - loss: 641270208.0000 - val_loss: 544883264.0000\n","Epoch 48/100\n","313/313 [==============================] - 1s 2ms/step - loss: 613143488.0000 - val_loss: 497554752.0000\n","Epoch 49/100\n","313/313 [==============================] - 1s 2ms/step - loss: 575733568.0000 - val_loss: 447957376.0000\n","Epoch 50/100\n","313/313 [==============================] - 1s 2ms/step - loss: 546511104.0000 - val_loss: 399147616.0000\n","Epoch 51/100\n","313/313 [==============================] - 1s 2ms/step - loss: 516137408.0000 - val_loss: 389578240.0000\n","Epoch 52/100\n","313/313 [==============================] - 1s 2ms/step - loss: 488699360.0000 - val_loss: 373003808.0000\n","Epoch 53/100\n","313/313 [==============================] - 1s 2ms/step - loss: 447357888.0000 - val_loss: 315859232.0000\n","Epoch 54/100\n","313/313 [==============================] - 1s 2ms/step - loss: 416643200.0000 - val_loss: 313460448.0000\n","Epoch 55/100\n","313/313 [==============================] - 1s 2ms/step - loss: 386744928.0000 - val_loss: 284484992.0000\n","Epoch 56/100\n","313/313 [==============================] - 1s 2ms/step - loss: 363731552.0000 - val_loss: 254681168.0000\n","Epoch 57/100\n","313/313 [==============================] - 1s 2ms/step - loss: 346046048.0000 - val_loss: 223703648.0000\n","Epoch 58/100\n","313/313 [==============================] - 1s 2ms/step - loss: 318523168.0000 - val_loss: 198488816.0000\n","Epoch 59/100\n","313/313 [==============================] - 1s 2ms/step - loss: 297895104.0000 - val_loss: 193105104.0000\n","Epoch 60/100\n","313/313 [==============================] - 1s 2ms/step - loss: 264428688.0000 - val_loss: 152589312.0000\n","Epoch 61/100\n","313/313 [==============================] - 1s 2ms/step - loss: 254577664.0000 - val_loss: 133961200.0000\n","Epoch 62/100\n","313/313 [==============================] - 1s 2ms/step - loss: 230453408.0000 - val_loss: 128756192.0000\n","Epoch 63/100\n","313/313 [==============================] - 1s 2ms/step - loss: 219277472.0000 - val_loss: 120917048.0000\n","Epoch 64/100\n","313/313 [==============================] - 1s 2ms/step - loss: 201120016.0000 - val_loss: 105384184.0000\n","Epoch 65/100\n","313/313 [==============================] - 1s 2ms/step - loss: 190285792.0000 - val_loss: 79792296.0000\n","Epoch 66/100\n","313/313 [==============================] - 1s 2ms/step - loss: 174781632.0000 - val_loss: 91496112.0000\n","Epoch 67/100\n","313/313 [==============================] - 1s 2ms/step - loss: 160597648.0000 - val_loss: 78178272.0000\n","Epoch 68/100\n","313/313 [==============================] - 1s 2ms/step - loss: 145399728.0000 - val_loss: 75764872.0000\n","Epoch 69/100\n","313/313 [==============================] - 1s 2ms/step - loss: 143684048.0000 - val_loss: 49917896.0000\n","Epoch 70/100\n","313/313 [==============================] - 1s 2ms/step - loss: 123031120.0000 - val_loss: 47755624.0000\n","Epoch 71/100\n","313/313 [==============================] - 1s 2ms/step - loss: 129274392.0000 - val_loss: 37654800.0000\n","Epoch 72/100\n","313/313 [==============================] - 0s 1ms/step - loss: 115225088.0000 - val_loss: 44408372.0000\n","Epoch 73/100\n","313/313 [==============================] - 1s 2ms/step - loss: 117562880.0000 - val_loss: 19866494.0000\n","Epoch 74/100\n","313/313 [==============================] - 1s 2ms/step - loss: 109730912.0000 - val_loss: 34025228.0000\n","Epoch 75/100\n","313/313 [==============================] - 0s 1ms/step - loss: 102325064.0000 - val_loss: 22198990.0000\n","Epoch 76/100\n","313/313 [==============================] - 1s 2ms/step - loss: 104029128.0000 - val_loss: 23276870.0000\n","Epoch 77/100\n","313/313 [==============================] - 1s 3ms/step - loss: 93876432.0000 - val_loss: 10392979.0000\n","Epoch 78/100\n","313/313 [==============================] - 1s 2ms/step - loss: 95029744.0000 - val_loss: 12908741.0000\n","Epoch 79/100\n","313/313 [==============================] - 0s 1ms/step - loss: 94308080.0000 - val_loss: 19598392.0000\n","Epoch 80/100\n","313/313 [==============================] - 0s 1ms/step - loss: 97312872.0000 - val_loss: 16232444.0000\n","Epoch 81/100\n","313/313 [==============================] - 0s 1ms/step - loss: 100542608.0000 - val_loss: 9803598.0000\n","Epoch 82/100\n","313/313 [==============================] - 0s 1ms/step - loss: 92741616.0000 - val_loss: 7857926.5000\n","Epoch 83/100\n","313/313 [==============================] - 1s 2ms/step - loss: 90899168.0000 - val_loss: 13386397.0000\n","Epoch 84/100\n","313/313 [==============================] - 1s 2ms/step - loss: 98600400.0000 - val_loss: 3814707.5000\n","Epoch 85/100\n","313/313 [==============================] - 1s 2ms/step - loss: 100273400.0000 - val_loss: 16688890.0000\n","Epoch 86/100\n","313/313 [==============================] - 1s 2ms/step - loss: 76995656.0000 - val_loss: 5456218.0000\n","Epoch 87/100\n","313/313 [==============================] - 1s 2ms/step - loss: 79046584.0000 - val_loss: 19570796.0000\n","Epoch 88/100\n","313/313 [==============================] - 1s 3ms/step - loss: 78175072.0000 - val_loss: 38483164.0000\n","Epoch 89/100\n","313/313 [==============================] - 1s 2ms/step - loss: 72249136.0000 - val_loss: 4702360.5000\n","Epoch 90/100\n","313/313 [==============================] - 1s 2ms/step - loss: 68617336.0000 - val_loss: 7718791.5000\n","Epoch 91/100\n","313/313 [==============================] - 0s 2ms/step - loss: 72161232.0000 - val_loss: 4166029.5000\n","Epoch 92/100\n","313/313 [==============================] - 0s 1ms/step - loss: 71822208.0000 - val_loss: 21942810.0000\n","Epoch 93/100\n","313/313 [==============================] - 0s 1ms/step - loss: 62194848.0000 - val_loss: 46707520.0000\n","Epoch 94/100\n","313/313 [==============================] - 0s 1ms/step - loss: 71729112.0000 - val_loss: 4246961.5000\n","Epoch 95/100\n","313/313 [==============================] - 0s 1ms/step - loss: 66805716.0000 - val_loss: 4582965.0000\n","Epoch 96/100\n","313/313 [==============================] - 0s 1ms/step - loss: 61109824.0000 - val_loss: 3755381.7500\n","Epoch 97/100\n","313/313 [==============================] - 0s 1ms/step - loss: 58987592.0000 - val_loss: 3990759.2500\n","Epoch 98/100\n","313/313 [==============================] - 1s 3ms/step - loss: 52317680.0000 - val_loss: 5757847.5000\n","Epoch 99/100\n","313/313 [==============================] - 1s 2ms/step - loss: 53836160.0000 - val_loss: 2002399.5000\n","Epoch 100/100\n","313/313 [==============================] - 0s 2ms/step - loss: 59843788.0000 - val_loss: 1321200.1250\n","Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_19 (Dense)            (None, 128)               3968      \n","                                                                 \n"," batch_normalization_11 (Bat  (None, 128)              512       \n"," chNormalization)                                                \n","                                                                 \n"," dense_20 (Dense)            (None, 64)                8256      \n","                                                                 \n"," batch_normalization_12 (Bat  (None, 64)               256       \n"," chNormalization)                                                \n","                                                                 \n"," dense_21 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 13,057\n","Trainable params: 12,673\n","Non-trainable params: 384\n","_________________________________________________________________\n","87/87 [==============================] - 0s 1ms/step\n","[[23124.215 ]\n"," [ 8235.725 ]\n"," [ 5584.4365]\n"," ...\n"," [11878.947 ]\n"," [ 3173.6963]\n"," [12223.416 ]]\n"]}],"source":["#build model 4\n","model = keras.models.Sequential([\n","    keras.layers.Dense(128, activation=\"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(64, activation=\"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(1)\n","])\n","model.compile(loss='mean_squared_error', \n","              optimizer='rmsprop')\n","\n","#fit model\n","history = model.fit(X_train, \n","                    y_train, \n","                    epochs= 100, \n","                    validation_data=(x_val, y_val))\n","\n","model.summary()\n","\n","#evaluate the model\n","print(model.predict(X_test))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[25005.]\n"," [ 9664.]\n"," [ 6053.]\n"," ...\n"," [12549.]\n"," [ 1204.]\n"," [13000.]]\n"]}],"source":["print(y_test)"]},{"cell_type":"markdown","metadata":{},"source":["### Model 5 (Main Model)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/300\n","313/313 [==============================] - 1s 1ms/step - loss: 1765815552.0000\n","Epoch 2/300\n","313/313 [==============================] - 0s 1ms/step - loss: 1226368384.0000\n","Epoch 3/300\n","313/313 [==============================] - 0s 1ms/step - loss: 586272192.0000\n","Epoch 4/300\n","313/313 [==============================] - 0s 1ms/step - loss: 225612992.0000\n","Epoch 5/300\n","313/313 [==============================] - 0s 1000us/step - loss: 129806144.0000\n","Epoch 6/300\n","313/313 [==============================] - 0s 1ms/step - loss: 96830472.0000\n","Epoch 7/300\n","313/313 [==============================] - 0s 1ms/step - loss: 78311072.0000\n","Epoch 8/300\n","313/313 [==============================] - 0s 1ms/step - loss: 74567400.0000\n","Epoch 9/300\n","313/313 [==============================] - 1s 2ms/step - loss: 75815808.0000\n","Epoch 10/300\n","313/313 [==============================] - 0s 1ms/step - loss: 74509368.0000\n","Epoch 11/300\n","313/313 [==============================] - 0s 1ms/step - loss: 72142768.0000\n","Epoch 12/300\n","313/313 [==============================] - 0s 1ms/step - loss: 56250060.0000\n","Epoch 13/300\n","313/313 [==============================] - 0s 1ms/step - loss: 54890908.0000\n","Epoch 14/300\n","313/313 [==============================] - 0s 1ms/step - loss: 65245340.0000\n","Epoch 15/300\n","313/313 [==============================] - 0s 1ms/step - loss: 64849912.0000\n","Epoch 16/300\n","313/313 [==============================] - 0s 1ms/step - loss: 63251744.0000\n","Epoch 17/300\n","313/313 [==============================] - 0s 1ms/step - loss: 52527248.0000\n","Epoch 18/300\n","313/313 [==============================] - 0s 1ms/step - loss: 59176172.0000\n","Epoch 19/300\n","313/313 [==============================] - 0s 1ms/step - loss: 58035716.0000\n","Epoch 20/300\n","313/313 [==============================] - 0s 1000us/step - loss: 52716740.0000\n","Epoch 21/300\n","313/313 [==============================] - 0s 1ms/step - loss: 52296848.0000\n","Epoch 22/300\n","313/313 [==============================] - 0s 1ms/step - loss: 56926992.0000\n","Epoch 23/300\n","313/313 [==============================] - 0s 948us/step - loss: 57763156.0000\n","Epoch 24/300\n","313/313 [==============================] - 0s 942us/step - loss: 54374104.0000\n","Epoch 25/300\n","313/313 [==============================] - 1s 2ms/step - loss: 50976492.0000\n","Epoch 26/300\n","313/313 [==============================] - 0s 1ms/step - loss: 49119280.0000\n","Epoch 27/300\n","313/313 [==============================] - 0s 900us/step - loss: 47720988.0000\n","Epoch 28/300\n","313/313 [==============================] - 0s 952us/step - loss: 49521184.0000\n","Epoch 29/300\n","313/313 [==============================] - 0s 859us/step - loss: 52804432.0000\n","Epoch 30/300\n","313/313 [==============================] - 0s 913us/step - loss: 46492080.0000\n","Epoch 31/300\n","313/313 [==============================] - 0s 868us/step - loss: 47791464.0000\n","Epoch 32/300\n","313/313 [==============================] - 0s 1ms/step - loss: 55673752.0000\n","Epoch 33/300\n","313/313 [==============================] - 0s 1ms/step - loss: 51053128.0000\n","Epoch 34/300\n","313/313 [==============================] - 0s 1ms/step - loss: 49538048.0000\n","Epoch 35/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45696036.0000\n","Epoch 36/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43216840.0000\n","Epoch 37/300\n","313/313 [==============================] - 0s 955us/step - loss: 44672804.0000\n","Epoch 38/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43222700.0000\n","Epoch 39/300\n","313/313 [==============================] - 0s 903us/step - loss: 51651916.0000\n","Epoch 40/300\n","313/313 [==============================] - 0s 961us/step - loss: 44471724.0000\n","Epoch 41/300\n","313/313 [==============================] - 0s 942us/step - loss: 42045096.0000\n","Epoch 42/300\n","313/313 [==============================] - 0s 868us/step - loss: 44189844.0000\n","Epoch 43/300\n","313/313 [==============================] - 0s 868us/step - loss: 41555812.0000\n","Epoch 44/300\n","313/313 [==============================] - 0s 865us/step - loss: 45612240.0000\n","Epoch 45/300\n","313/313 [==============================] - 0s 923us/step - loss: 43165540.0000\n","Epoch 46/300\n","313/313 [==============================] - 0s 968us/step - loss: 41199248.0000\n","Epoch 47/300\n","313/313 [==============================] - 0s 922us/step - loss: 45255128.0000\n","Epoch 48/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43265228.0000\n","Epoch 49/300\n","313/313 [==============================] - 0s 964us/step - loss: 42914032.0000\n","Epoch 50/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41679252.0000\n","Epoch 51/300\n","313/313 [==============================] - 0s 974us/step - loss: 43945524.0000\n","Epoch 52/300\n","313/313 [==============================] - 0s 939us/step - loss: 42574536.0000\n","Epoch 53/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42215680.0000\n","Epoch 54/300\n","313/313 [==============================] - 0s 904us/step - loss: 46222364.0000\n","Epoch 55/300\n","313/313 [==============================] - 0s 942us/step - loss: 43773648.0000\n","Epoch 56/300\n","313/313 [==============================] - 0s 923us/step - loss: 41903316.0000\n","Epoch 57/300\n","313/313 [==============================] - 0s 961us/step - loss: 42967088.0000\n","Epoch 58/300\n","313/313 [==============================] - 0s 1ms/step - loss: 46599708.0000\n","Epoch 59/300\n","313/313 [==============================] - 0s 885us/step - loss: 41416964.0000\n","Epoch 60/300\n","313/313 [==============================] - 0s 939us/step - loss: 49795600.0000\n","Epoch 61/300\n","313/313 [==============================] - 0s 880us/step - loss: 44940900.0000\n","Epoch 62/300\n","313/313 [==============================] - 0s 936us/step - loss: 51362416.0000\n","Epoch 63/300\n","313/313 [==============================] - 0s 996us/step - loss: 40882964.0000\n","Epoch 64/300\n","313/313 [==============================] - 0s 996us/step - loss: 43997800.0000\n","Epoch 65/300\n","313/313 [==============================] - 0s 865us/step - loss: 45937364.0000\n","Epoch 66/300\n","313/313 [==============================] - 0s 920us/step - loss: 43167056.0000\n","Epoch 67/300\n","313/313 [==============================] - 0s 822us/step - loss: 45054024.0000\n","Epoch 68/300\n","313/313 [==============================] - 0s 961us/step - loss: 50029092.0000\n","Epoch 69/300\n","313/313 [==============================] - 0s 948us/step - loss: 48609168.0000\n","Epoch 70/300\n","313/313 [==============================] - 0s 836us/step - loss: 39268576.0000\n","Epoch 71/300\n","313/313 [==============================] - 0s 859us/step - loss: 33780168.0000\n","Epoch 72/300\n","313/313 [==============================] - 0s 1ms/step - loss: 50291580.0000\n","Epoch 73/300\n","313/313 [==============================] - 0s 838us/step - loss: 43507772.0000\n","Epoch 74/300\n","313/313 [==============================] - 0s 948us/step - loss: 42181868.0000\n","Epoch 75/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42795640.0000\n","Epoch 76/300\n","313/313 [==============================] - 0s 964us/step - loss: 44009456.0000\n","Epoch 77/300\n","313/313 [==============================] - 0s 980us/step - loss: 49506348.0000\n","Epoch 78/300\n","313/313 [==============================] - 0s 896us/step - loss: 38329320.0000\n","Epoch 79/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45128292.0000\n","Epoch 80/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41844524.0000\n","Epoch 81/300\n","313/313 [==============================] - 0s 965us/step - loss: 40216700.0000\n","Epoch 82/300\n","313/313 [==============================] - 0s 964us/step - loss: 42515624.0000\n","Epoch 83/300\n","313/313 [==============================] - 0s 1ms/step - loss: 47661768.0000\n","Epoch 84/300\n","313/313 [==============================] - 0s 945us/step - loss: 37644936.0000\n","Epoch 85/300\n","313/313 [==============================] - 0s 875us/step - loss: 43435408.0000\n","Epoch 86/300\n","313/313 [==============================] - 0s 897us/step - loss: 45432532.0000\n","Epoch 87/300\n","313/313 [==============================] - 0s 945us/step - loss: 42273532.0000\n","Epoch 88/300\n","313/313 [==============================] - 0s 1000us/step - loss: 41685944.0000\n","Epoch 89/300\n","313/313 [==============================] - 0s 947us/step - loss: 37369396.0000\n","Epoch 90/300\n","313/313 [==============================] - 0s 952us/step - loss: 42662180.0000\n","Epoch 91/300\n","313/313 [==============================] - 0s 987us/step - loss: 44825448.0000\n","Epoch 92/300\n","313/313 [==============================] - 0s 964us/step - loss: 43347760.0000\n","Epoch 93/300\n","313/313 [==============================] - 0s 913us/step - loss: 40004040.0000\n","Epoch 94/300\n","313/313 [==============================] - 0s 900us/step - loss: 55872800.0000\n","Epoch 95/300\n","313/313 [==============================] - 0s 897us/step - loss: 41911788.0000\n","Epoch 96/300\n","313/313 [==============================] - 0s 826us/step - loss: 47187708.0000\n","Epoch 97/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37770124.0000\n","Epoch 98/300\n","313/313 [==============================] - 0s 939us/step - loss: 42533628.0000\n","Epoch 99/300\n","313/313 [==============================] - 0s 926us/step - loss: 41047340.0000\n","Epoch 100/300\n","313/313 [==============================] - 0s 1ms/step - loss: 50706208.0000\n","Epoch 101/300\n","313/313 [==============================] - 0s 977us/step - loss: 42577232.0000\n","Epoch 102/300\n","313/313 [==============================] - 0s 910us/step - loss: 44975332.0000\n","Epoch 103/300\n","313/313 [==============================] - 0s 944us/step - loss: 41189196.0000\n","Epoch 104/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43310540.0000\n","Epoch 105/300\n","313/313 [==============================] - 0s 936us/step - loss: 43296688.0000\n","Epoch 106/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44503668.0000\n","Epoch 107/300\n","313/313 [==============================] - 0s 2ms/step - loss: 44129756.0000\n","Epoch 108/300\n","313/313 [==============================] - 1s 3ms/step - loss: 39920064.0000\n","Epoch 109/300\n","313/313 [==============================] - 1s 2ms/step - loss: 41386044.0000\n","Epoch 110/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43842012.0000\n","Epoch 111/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37966692.0000\n","Epoch 112/300\n","313/313 [==============================] - 1s 2ms/step - loss: 46009172.0000\n","Epoch 113/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45030956.0000\n","Epoch 114/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43438708.0000\n","Epoch 115/300\n","313/313 [==============================] - 0s 2ms/step - loss: 37274768.0000\n","Epoch 116/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39738308.0000\n","Epoch 117/300\n","313/313 [==============================] - 0s 2ms/step - loss: 45151596.0000\n","Epoch 118/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44886436.0000\n","Epoch 119/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45198968.0000\n","Epoch 120/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40418616.0000\n","Epoch 121/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37297104.0000\n","Epoch 122/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42184328.0000\n","Epoch 123/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41117496.0000\n","Epoch 124/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37544416.0000\n","Epoch 125/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37118712.0000\n","Epoch 126/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41484776.0000\n","Epoch 127/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39778508.0000\n","Epoch 128/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42171292.0000\n","Epoch 129/300\n","313/313 [==============================] - 0s 2ms/step - loss: 49367572.0000\n","Epoch 130/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45942232.0000\n","Epoch 131/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43716012.0000\n","Epoch 132/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41369288.0000\n","Epoch 133/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39876244.0000\n","Epoch 134/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44411552.0000\n","Epoch 135/300\n","313/313 [==============================] - 1s 2ms/step - loss: 44591996.0000\n","Epoch 136/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39312900.0000\n","Epoch 137/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40729108.0000\n","Epoch 138/300\n","313/313 [==============================] - 1s 2ms/step - loss: 42304528.0000\n","Epoch 139/300\n","313/313 [==============================] - 1s 2ms/step - loss: 44398372.0000\n","Epoch 140/300\n","313/313 [==============================] - 0s 2ms/step - loss: 48783488.0000\n","Epoch 141/300\n","313/313 [==============================] - 1s 2ms/step - loss: 41072688.0000\n","Epoch 142/300\n","313/313 [==============================] - 1s 2ms/step - loss: 38837736.0000\n","Epoch 143/300\n","313/313 [==============================] - 0s 2ms/step - loss: 35784988.0000\n","Epoch 144/300\n","313/313 [==============================] - 1s 2ms/step - loss: 42527644.0000\n","Epoch 145/300\n","313/313 [==============================] - 1s 2ms/step - loss: 38099092.0000\n","Epoch 146/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41997896.0000\n","Epoch 147/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40814544.0000\n","Epoch 148/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44573180.0000\n","Epoch 149/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41198564.0000\n","Epoch 150/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40110840.0000\n","Epoch 151/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43500244.0000\n","Epoch 152/300\n","313/313 [==============================] - 1s 2ms/step - loss: 40060248.0000\n","Epoch 153/300\n","313/313 [==============================] - 0s 963us/step - loss: 46533360.0000\n","Epoch 154/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41650996.0000\n","Epoch 155/300\n","313/313 [==============================] - 0s 878us/step - loss: 39902544.0000\n","Epoch 156/300\n","313/313 [==============================] - 0s 932us/step - loss: 45010244.0000\n","Epoch 157/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42434768.0000\n","Epoch 158/300\n","313/313 [==============================] - 0s 956us/step - loss: 47355996.0000\n","Epoch 159/300\n","313/313 [==============================] - 0s 952us/step - loss: 38130376.0000\n","Epoch 160/300\n","313/313 [==============================] - 0s 1ms/step - loss: 36330816.0000\n","Epoch 161/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41342520.0000\n","Epoch 162/300\n","313/313 [==============================] - 0s 971us/step - loss: 36514772.0000\n","Epoch 163/300\n","313/313 [==============================] - 0s 931us/step - loss: 42789156.0000\n","Epoch 164/300\n","313/313 [==============================] - 1s 2ms/step - loss: 38068408.0000\n","Epoch 165/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37599480.0000\n","Epoch 166/300\n","313/313 [==============================] - 1s 2ms/step - loss: 41183780.0000\n","Epoch 167/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43395492.0000\n","Epoch 168/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42449656.0000\n","Epoch 169/300\n","313/313 [==============================] - 0s 2ms/step - loss: 38635272.0000\n","Epoch 170/300\n","313/313 [==============================] - 0s 2ms/step - loss: 44493964.0000\n","Epoch 171/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41874468.0000\n","Epoch 172/300\n","313/313 [==============================] - 1s 2ms/step - loss: 45041944.0000\n","Epoch 173/300\n","313/313 [==============================] - 0s 1ms/step - loss: 36758972.0000\n","Epoch 174/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40165548.0000\n","Epoch 175/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40559900.0000\n","Epoch 176/300\n","313/313 [==============================] - 0s 2ms/step - loss: 41797580.0000\n","Epoch 177/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39813512.0000\n","Epoch 178/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45965128.0000\n","Epoch 179/300\n","313/313 [==============================] - 0s 2ms/step - loss: 37748664.0000\n","Epoch 180/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38646640.0000\n","Epoch 181/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44630148.0000\n","Epoch 182/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38944452.0000\n","Epoch 183/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38961600.0000\n","Epoch 184/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38162864.0000\n","Epoch 185/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40176492.0000\n","Epoch 186/300\n","313/313 [==============================] - 1s 2ms/step - loss: 41104672.0000\n","Epoch 187/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38142584.0000\n","Epoch 188/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42160256.0000\n","Epoch 189/300\n","313/313 [==============================] - 1s 2ms/step - loss: 41451220.0000\n","Epoch 190/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41142932.0000\n","Epoch 191/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44465840.0000\n","Epoch 192/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41549684.0000\n","Epoch 193/300\n","313/313 [==============================] - 0s 2ms/step - loss: 45464256.0000\n","Epoch 194/300\n","313/313 [==============================] - 1s 2ms/step - loss: 39123016.0000\n","Epoch 195/300\n","313/313 [==============================] - 0s 1ms/step - loss: 35155672.0000\n","Epoch 196/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39858176.0000\n","Epoch 197/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42423288.0000\n","Epoch 198/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43397028.0000\n","Epoch 199/300\n","313/313 [==============================] - 0s 1ms/step - loss: 48492164.0000\n","Epoch 200/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45467956.0000\n","Epoch 201/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42329332.0000\n","Epoch 202/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43161768.0000\n","Epoch 203/300\n","313/313 [==============================] - 1s 2ms/step - loss: 42019220.0000\n","Epoch 204/300\n","313/313 [==============================] - 0s 990us/step - loss: 44495704.0000\n","Epoch 205/300\n","313/313 [==============================] - 0s 1000us/step - loss: 39849748.0000\n","Epoch 206/300\n","313/313 [==============================] - 0s 1000us/step - loss: 40705676.0000\n","Epoch 207/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41820388.0000\n","Epoch 208/300\n","313/313 [==============================] - 0s 1ms/step - loss: 49463488.0000\n","Epoch 209/300\n","313/313 [==============================] - 0s 1ms/step - loss: 46686548.0000\n","Epoch 210/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42691192.0000\n","Epoch 211/300\n","313/313 [==============================] - 0s 979us/step - loss: 41346964.0000\n","Epoch 212/300\n","313/313 [==============================] - 0s 964us/step - loss: 37570452.0000\n","Epoch 213/300\n","313/313 [==============================] - 0s 945us/step - loss: 43945928.0000\n","Epoch 214/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44182180.0000\n","Epoch 215/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39816336.0000\n","Epoch 216/300\n","313/313 [==============================] - 0s 989us/step - loss: 36997608.0000\n","Epoch 217/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41410976.0000\n","Epoch 218/300\n","313/313 [==============================] - 0s 968us/step - loss: 44758448.0000\n","Epoch 219/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44358656.0000\n","Epoch 220/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42036512.0000\n","Epoch 221/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37610152.0000\n","Epoch 222/300\n","313/313 [==============================] - 0s 989us/step - loss: 37721736.0000\n","Epoch 223/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40086772.0000\n","Epoch 224/300\n","313/313 [==============================] - 0s 2ms/step - loss: 39258180.0000\n","Epoch 225/300\n","313/313 [==============================] - 1s 2ms/step - loss: 39712916.0000\n","Epoch 226/300\n","313/313 [==============================] - 1s 2ms/step - loss: 37065596.0000\n","Epoch 227/300\n","313/313 [==============================] - 0s 2ms/step - loss: 39715228.0000\n","Epoch 228/300\n","313/313 [==============================] - 1s 2ms/step - loss: 44479344.0000\n","Epoch 229/300\n","313/313 [==============================] - 1s 2ms/step - loss: 36463732.0000\n","Epoch 230/300\n","313/313 [==============================] - 0s 2ms/step - loss: 38704336.0000\n","Epoch 231/300\n","313/313 [==============================] - 1s 2ms/step - loss: 39550504.0000\n","Epoch 232/300\n","313/313 [==============================] - 0s 2ms/step - loss: 36886588.0000\n","Epoch 233/300\n","313/313 [==============================] - 1s 2ms/step - loss: 41630236.0000\n","Epoch 234/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39670072.0000\n","Epoch 235/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43996500.0000\n","Epoch 236/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41640924.0000\n","Epoch 237/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39053428.0000\n","Epoch 238/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43027944.0000\n","Epoch 239/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38113600.0000\n","Epoch 240/300\n","313/313 [==============================] - 1s 2ms/step - loss: 43206260.0000\n","Epoch 241/300\n","313/313 [==============================] - 0s 2ms/step - loss: 38972628.0000\n","Epoch 242/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40513616.0000\n","Epoch 243/300\n","313/313 [==============================] - 0s 1ms/step - loss: 49863836.0000\n","Epoch 244/300\n","313/313 [==============================] - 0s 2ms/step - loss: 40206384.0000\n","Epoch 245/300\n","313/313 [==============================] - 0s 1ms/step - loss: 36249216.0000\n","Epoch 246/300\n","313/313 [==============================] - 1s 2ms/step - loss: 38640732.0000\n","Epoch 247/300\n","313/313 [==============================] - 1s 2ms/step - loss: 42983036.0000\n","Epoch 248/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41402756.0000\n","Epoch 249/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42390536.0000\n","Epoch 250/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41602592.0000\n","Epoch 251/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39598772.0000\n","Epoch 252/300\n","313/313 [==============================] - 1s 2ms/step - loss: 37880164.0000\n","Epoch 253/300\n","313/313 [==============================] - 1s 2ms/step - loss: 40481016.0000\n","Epoch 254/300\n","313/313 [==============================] - 1s 2ms/step - loss: 37147340.0000\n","Epoch 255/300\n","313/313 [==============================] - 1s 3ms/step - loss: 42792892.0000\n","Epoch 256/300\n","313/313 [==============================] - 1s 2ms/step - loss: 40413644.0000\n","Epoch 257/300\n","313/313 [==============================] - 0s 2ms/step - loss: 42405128.0000\n","Epoch 258/300\n","313/313 [==============================] - 1s 2ms/step - loss: 42943060.0000\n","Epoch 259/300\n","313/313 [==============================] - 0s 996us/step - loss: 38136392.0000\n","Epoch 260/300\n","313/313 [==============================] - 0s 932us/step - loss: 38847180.0000\n","Epoch 261/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40164264.0000\n","Epoch 262/300\n","313/313 [==============================] - 1s 2ms/step - loss: 44967712.0000\n","Epoch 263/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40676800.0000\n","Epoch 264/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37869352.0000\n","Epoch 265/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42666080.0000\n","Epoch 266/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43440676.0000\n","Epoch 267/300\n","313/313 [==============================] - 0s 1ms/step - loss: 50063680.0000\n","Epoch 268/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44868056.0000\n","Epoch 269/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39304684.0000\n","Epoch 270/300\n","313/313 [==============================] - 0s 977us/step - loss: 44515048.0000\n","Epoch 271/300\n","313/313 [==============================] - 0s 987us/step - loss: 47278624.0000\n","Epoch 272/300\n","313/313 [==============================] - 0s 964us/step - loss: 37091812.0000\n","Epoch 273/300\n","313/313 [==============================] - 0s 900us/step - loss: 40063992.0000\n","Epoch 274/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43846084.0000\n","Epoch 275/300\n","313/313 [==============================] - 0s 1ms/step - loss: 48264104.0000\n","Epoch 276/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43371580.0000\n","Epoch 277/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45125624.0000\n","Epoch 278/300\n","313/313 [==============================] - 0s 923us/step - loss: 42754664.0000\n","Epoch 279/300\n","313/313 [==============================] - 0s 948us/step - loss: 46964740.0000\n","Epoch 280/300\n","313/313 [==============================] - 0s 980us/step - loss: 42815652.0000\n","Epoch 281/300\n","313/313 [==============================] - 0s 872us/step - loss: 37612996.0000\n","Epoch 282/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40836428.0000\n","Epoch 283/300\n","313/313 [==============================] - 0s 945us/step - loss: 41293284.0000\n","Epoch 284/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44045176.0000\n","Epoch 285/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43084480.0000\n","Epoch 286/300\n","313/313 [==============================] - 0s 881us/step - loss: 40076092.0000\n","Epoch 287/300\n","313/313 [==============================] - 0s 920us/step - loss: 44038816.0000\n","Epoch 288/300\n","313/313 [==============================] - 0s 952us/step - loss: 39735924.0000\n","Epoch 289/300\n","313/313 [==============================] - 0s 939us/step - loss: 42518592.0000\n","Epoch 290/300\n","313/313 [==============================] - 0s 926us/step - loss: 42801500.0000\n","Epoch 291/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41853952.0000\n","Epoch 292/300\n","313/313 [==============================] - 0s 1ms/step - loss: 34811052.0000\n","Epoch 293/300\n","313/313 [==============================] - 0s 900us/step - loss: 40225064.0000\n","Epoch 294/300\n","313/313 [==============================] - 0s 936us/step - loss: 42780052.0000\n","Epoch 295/300\n","313/313 [==============================] - 0s 961us/step - loss: 44847724.0000\n","Epoch 296/300\n","313/313 [==============================] - 0s 961us/step - loss: 39579592.0000\n","Epoch 297/300\n","313/313 [==============================] - 0s 931us/step - loss: 40213284.0000\n","Epoch 298/300\n","313/313 [==============================] - 0s 865us/step - loss: 43316584.0000\n","Epoch 299/300\n","313/313 [==============================] - 0s 926us/step - loss: 42615716.0000\n","Epoch 300/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37976752.0000\n","Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_22 (Dense)            (None, 30)                930       \n","                                                                 \n"," batch_normalization_13 (Bat  (None, 30)               120       \n"," chNormalization)                                                \n","                                                                 \n"," dense_23 (Dense)            (None, 1)                 31        \n","                                                                 \n","=================================================================\n","Total params: 1,081\n","Trainable params: 1,021\n","Non-trainable params: 60\n","_________________________________________________________________\n","87/87 [==============================] - 0s 663us/step\n","[[24415.287 ]\n"," [10630.508 ]\n"," [ 8027.8364]\n"," ...\n"," [13120.918 ]\n"," [ 1357.9786]\n"," [13059.038 ]]\n"]}],"source":["# MAIN MODEL \n","# evaluate model with standardized dataset\n","from sklearn import preprocessing\n","# preprocess the data\n","scaler = preprocessing.StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","y_train = y_train.reshape(-1,1)\n","y_test = y_test\n","\n","\n","tf.random.set_seed(42)\n","\n","#define baseline model\n","model = keras.models.Sequential([\n","    keras.layers.Dense(units= 30, \n","                       input_shape= (30,), \n","                       activation= \"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(1)\n","])\n","\n","model.compile(loss='mean_squared_error', \n","              optimizer= tf.keras.optimizers.Adam(0.02))\n","\n","#fit model\n","history = model.fit(X_train, \n","                    y_train, \n","                    epochs= 300)\n","\n","model.summary()\n","\n","#test model\n","print(model.predict(X_test))\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[25005.]\n"," [ 9664.]\n"," [ 6053.]\n"," ...\n"," [12549.]\n"," [ 1204.]\n"," [13000.]]\n"]}],"source":["print(y_test)"]},{"cell_type":"markdown","metadata":{},"source":["### Model 6"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/300\n","313/313 [==============================] - 1s 1ms/step - loss: 1841843328.0000\n","Epoch 2/300\n","313/313 [==============================] - 0s 1ms/step - loss: 1680333952.0000\n","Epoch 3/300\n","313/313 [==============================] - 0s 1ms/step - loss: 1399853568.0000\n","Epoch 4/300\n","313/313 [==============================] - 0s 1ms/step - loss: 1066661312.0000\n","Epoch 5/300\n","313/313 [==============================] - 0s 1ms/step - loss: 753653056.0000\n","Epoch 6/300\n","313/313 [==============================] - 0s 1ms/step - loss: 491911584.0000\n","Epoch 7/300\n","313/313 [==============================] - 0s 955us/step - loss: 305711744.0000\n","Epoch 8/300\n","313/313 [==============================] - 0s 1ms/step - loss: 195472720.0000\n","Epoch 9/300\n","313/313 [==============================] - 0s 1ms/step - loss: 145372464.0000\n","Epoch 10/300\n","313/313 [==============================] - 0s 1ms/step - loss: 119306280.0000\n","Epoch 11/300\n","313/313 [==============================] - 0s 996us/step - loss: 108211864.0000\n","Epoch 12/300\n","313/313 [==============================] - 0s 1ms/step - loss: 84647408.0000\n","Epoch 13/300\n","313/313 [==============================] - 0s 1ms/step - loss: 77465488.0000\n","Epoch 14/300\n","313/313 [==============================] - 0s 1ms/step - loss: 87338200.0000\n","Epoch 15/300\n","313/313 [==============================] - 0s 948us/step - loss: 86703872.0000\n","Epoch 16/300\n","313/313 [==============================] - 0s 974us/step - loss: 82835888.0000\n","Epoch 17/300\n","313/313 [==============================] - 0s 1ms/step - loss: 68335224.0000\n","Epoch 18/300\n","313/313 [==============================] - 0s 1ms/step - loss: 75565864.0000\n","Epoch 19/300\n","313/313 [==============================] - 0s 1ms/step - loss: 72591280.0000\n","Epoch 20/300\n","313/313 [==============================] - 1s 2ms/step - loss: 65680128.0000\n","Epoch 21/300\n","313/313 [==============================] - 0s 1ms/step - loss: 64001772.0000\n","Epoch 22/300\n","313/313 [==============================] - 0s 1000us/step - loss: 68993392.0000\n","Epoch 23/300\n","313/313 [==============================] - 0s 913us/step - loss: 68914216.0000\n","Epoch 24/300\n","313/313 [==============================] - 0s 1ms/step - loss: 64806420.0000\n","Epoch 25/300\n","313/313 [==============================] - 0s 1ms/step - loss: 60308208.0000\n","Epoch 26/300\n","313/313 [==============================] - 0s 1ms/step - loss: 57799324.0000\n","Epoch 27/300\n","313/313 [==============================] - 0s 995us/step - loss: 55805856.0000\n","Epoch 28/300\n","313/313 [==============================] - 0s 910us/step - loss: 57790092.0000\n","Epoch 29/300\n","313/313 [==============================] - 0s 1ms/step - loss: 60804804.0000\n","Epoch 30/300\n","313/313 [==============================] - 0s 1ms/step - loss: 53324080.0000\n","Epoch 31/300\n","313/313 [==============================] - 0s 1ms/step - loss: 54259504.0000\n","Epoch 32/300\n","313/313 [==============================] - 0s 1ms/step - loss: 62858032.0000\n","Epoch 33/300\n","313/313 [==============================] - 0s 1ms/step - loss: 57491492.0000\n","Epoch 34/300\n","313/313 [==============================] - 0s 904us/step - loss: 55945956.0000\n","Epoch 35/300\n","313/313 [==============================] - 0s 1000us/step - loss: 51474116.0000\n","Epoch 36/300\n","313/313 [==============================] - 0s 993us/step - loss: 47744400.0000\n","Epoch 37/300\n","313/313 [==============================] - 0s 980us/step - loss: 49739548.0000\n","Epoch 38/300\n","313/313 [==============================] - 0s 954us/step - loss: 48358464.0000\n","Epoch 39/300\n","313/313 [==============================] - 0s 1ms/step - loss: 56678520.0000\n","Epoch 40/300\n","313/313 [==============================] - 0s 1ms/step - loss: 48811872.0000\n","Epoch 41/300\n","313/313 [==============================] - 0s 836us/step - loss: 46011800.0000\n","Epoch 42/300\n","313/313 [==============================] - 0s 881us/step - loss: 48568452.0000\n","Epoch 43/300\n","313/313 [==============================] - 0s 888us/step - loss: 45213588.0000\n","Epoch 44/300\n","313/313 [==============================] - 0s 947us/step - loss: 50104236.0000\n","Epoch 45/300\n","313/313 [==============================] - 0s 961us/step - loss: 46850208.0000\n","Epoch 46/300\n","313/313 [==============================] - 0s 868us/step - loss: 44787268.0000\n","Epoch 47/300\n","313/313 [==============================] - 0s 891us/step - loss: 49137904.0000\n","Epoch 48/300\n","313/313 [==============================] - 0s 961us/step - loss: 46783228.0000\n","Epoch 49/300\n","313/313 [==============================] - 0s 1ms/step - loss: 46479564.0000\n","Epoch 50/300\n","313/313 [==============================] - 0s 862us/step - loss: 44873232.0000\n","Epoch 51/300\n","313/313 [==============================] - 0s 955us/step - loss: 47405036.0000\n","Epoch 52/300\n","313/313 [==============================] - 0s 846us/step - loss: 45707832.0000\n","Epoch 53/300\n","313/313 [==============================] - 0s 892us/step - loss: 44821064.0000\n","Epoch 54/300\n","313/313 [==============================] - 0s 932us/step - loss: 49378732.0000\n","Epoch 55/300\n","313/313 [==============================] - 0s 916us/step - loss: 46259968.0000\n","Epoch 56/300\n","313/313 [==============================] - 0s 859us/step - loss: 44408452.0000\n","Epoch 57/300\n","313/313 [==============================] - 0s 942us/step - loss: 45360688.0000\n","Epoch 58/300\n","313/313 [==============================] - 0s 969us/step - loss: 49357472.0000\n","Epoch 59/300\n","313/313 [==============================] - 0s 875us/step - loss: 43684408.0000\n","Epoch 60/300\n","313/313 [==============================] - 0s 872us/step - loss: 52834596.0000\n","Epoch 61/300\n","313/313 [==============================] - 0s 916us/step - loss: 46995432.0000\n","Epoch 62/300\n","313/313 [==============================] - 0s 941us/step - loss: 53980716.0000\n","Epoch 63/300\n","313/313 [==============================] - 0s 945us/step - loss: 43045172.0000\n","Epoch 64/300\n","313/313 [==============================] - 0s 900us/step - loss: 46392860.0000\n","Epoch 65/300\n","313/313 [==============================] - 0s 971us/step - loss: 47905640.0000\n","Epoch 66/300\n","313/313 [==============================] - 0s 923us/step - loss: 45452732.0000\n","Epoch 67/300\n","313/313 [==============================] - 0s 907us/step - loss: 47084452.0000\n","Epoch 68/300\n","313/313 [==============================] - 0s 942us/step - loss: 52019684.0000\n","Epoch 69/300\n","313/313 [==============================] - 0s 996us/step - loss: 50653656.0000\n","Epoch 70/300\n","313/313 [==============================] - 0s 894us/step - loss: 40930852.0000\n","Epoch 71/300\n","313/313 [==============================] - 0s 971us/step - loss: 35390396.0000\n","Epoch 72/300\n","313/313 [==============================] - 0s 939us/step - loss: 52406640.0000\n","Epoch 73/300\n","313/313 [==============================] - 0s 881us/step - loss: 45168312.0000\n","Epoch 74/300\n","313/313 [==============================] - 0s 939us/step - loss: 43711924.0000\n","Epoch 75/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44455884.0000\n","Epoch 76/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45434700.0000\n","Epoch 77/300\n","313/313 [==============================] - 0s 875us/step - loss: 51148392.0000\n","Epoch 78/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39667884.0000\n","Epoch 79/300\n","313/313 [==============================] - 0s 913us/step - loss: 46509292.0000\n","Epoch 80/300\n","313/313 [==============================] - 0s 968us/step - loss: 43135024.0000\n","Epoch 81/300\n","313/313 [==============================] - 0s 926us/step - loss: 41576428.0000\n","Epoch 82/300\n","313/313 [==============================] - 0s 964us/step - loss: 43772464.0000\n","Epoch 83/300\n","313/313 [==============================] - 0s 1ms/step - loss: 48965664.0000\n","Epoch 84/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38920872.0000\n","Epoch 85/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44742372.0000\n","Epoch 86/300\n","313/313 [==============================] - 1s 2ms/step - loss: 46775952.0000\n","Epoch 87/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43377984.0000\n","Epoch 88/300\n","313/313 [==============================] - 0s 932us/step - loss: 42743492.0000\n","Epoch 89/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38484420.0000\n","Epoch 90/300\n","313/313 [==============================] - 0s 955us/step - loss: 43749804.0000\n","Epoch 91/300\n","313/313 [==============================] - 0s 920us/step - loss: 46102444.0000\n","Epoch 92/300\n","313/313 [==============================] - 0s 907us/step - loss: 44493492.0000\n","Epoch 93/300\n","313/313 [==============================] - 0s 920us/step - loss: 40885496.0000\n","Epoch 94/300\n","313/313 [==============================] - 0s 888us/step - loss: 56918152.0000\n","Epoch 95/300\n","313/313 [==============================] - 0s 865us/step - loss: 42974868.0000\n","Epoch 96/300\n","313/313 [==============================] - 0s 977us/step - loss: 48165528.0000\n","Epoch 97/300\n","313/313 [==============================] - 0s 922us/step - loss: 38582164.0000\n","Epoch 98/300\n","313/313 [==============================] - 0s 900us/step - loss: 43305948.0000\n","Epoch 99/300\n","313/313 [==============================] - 0s 907us/step - loss: 42205856.0000\n","Epoch 100/300\n","313/313 [==============================] - 0s 1ms/step - loss: 51591260.0000\n","Epoch 101/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43310104.0000\n","Epoch 102/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45669252.0000\n","Epoch 103/300\n","313/313 [==============================] - 0s 958us/step - loss: 42001552.0000\n","Epoch 104/300\n","313/313 [==============================] - 0s 918us/step - loss: 44044092.0000\n","Epoch 105/300\n","313/313 [==============================] - 0s 936us/step - loss: 43843736.0000\n","Epoch 106/300\n","313/313 [==============================] - 0s 907us/step - loss: 45114756.0000\n","Epoch 107/300\n","313/313 [==============================] - 0s 926us/step - loss: 44919732.0000\n","Epoch 108/300\n","313/313 [==============================] - 0s 900us/step - loss: 40611532.0000\n","Epoch 109/300\n","313/313 [==============================] - 0s 907us/step - loss: 42053572.0000\n","Epoch 110/300\n","313/313 [==============================] - 0s 989us/step - loss: 44468432.0000\n","Epoch 111/300\n","313/313 [==============================] - 0s 855us/step - loss: 38532500.0000\n","Epoch 112/300\n","313/313 [==============================] - 0s 1ms/step - loss: 46686080.0000\n","Epoch 113/300\n","313/313 [==============================] - 0s 974us/step - loss: 45609476.0000\n","Epoch 114/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44044832.0000\n","Epoch 115/300\n","313/313 [==============================] - 0s 968us/step - loss: 37742324.0000\n","Epoch 116/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40137604.0000\n","Epoch 117/300\n","313/313 [==============================] - 0s 942us/step - loss: 45690504.0000\n","Epoch 118/300\n","313/313 [==============================] - 0s 932us/step - loss: 45377280.0000\n","Epoch 119/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45559940.0000\n","Epoch 120/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40886376.0000\n","Epoch 121/300\n","313/313 [==============================] - 0s 996us/step - loss: 37938596.0000\n","Epoch 122/300\n","313/313 [==============================] - 0s 952us/step - loss: 42681852.0000\n","Epoch 123/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41378068.0000\n","Epoch 124/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37693416.0000\n","Epoch 125/300\n","313/313 [==============================] - 0s 961us/step - loss: 37571084.0000\n","Epoch 126/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41912388.0000\n","Epoch 127/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40212696.0000\n","Epoch 128/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42545080.0000\n","Epoch 129/300\n","313/313 [==============================] - 0s 936us/step - loss: 49917040.0000\n","Epoch 130/300\n","313/313 [==============================] - 0s 904us/step - loss: 46344504.0000\n","Epoch 131/300\n","313/313 [==============================] - 0s 987us/step - loss: 44031636.0000\n","Epoch 132/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41725332.0000\n","Epoch 133/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40313212.0000\n","Epoch 134/300\n","313/313 [==============================] - 0s 952us/step - loss: 44767404.0000\n","Epoch 135/300\n","313/313 [==============================] - 0s 939us/step - loss: 45044128.0000\n","Epoch 136/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39507572.0000\n","Epoch 137/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41031452.0000\n","Epoch 138/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42561900.0000\n","Epoch 139/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44791192.0000\n","Epoch 140/300\n","313/313 [==============================] - 0s 1ms/step - loss: 49042212.0000\n","Epoch 141/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41345224.0000\n","Epoch 142/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39272332.0000\n","Epoch 143/300\n","313/313 [==============================] - 1s 2ms/step - loss: 36213124.0000\n","Epoch 144/300\n","313/313 [==============================] - 1s 4ms/step - loss: 42887708.0000\n","Epoch 145/300\n","313/313 [==============================] - 1s 2ms/step - loss: 38288164.0000\n","Epoch 146/300\n","313/313 [==============================] - 1s 2ms/step - loss: 42401176.0000\n","Epoch 147/300\n","313/313 [==============================] - 1s 2ms/step - loss: 41295140.0000\n","Epoch 148/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44933528.0000\n","Epoch 149/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41537184.0000\n","Epoch 150/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40383664.0000\n","Epoch 151/300\n","313/313 [==============================] - 0s 2ms/step - loss: 43892300.0000\n","Epoch 152/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40558496.0000\n","Epoch 153/300\n","313/313 [==============================] - 0s 1ms/step - loss: 46856376.0000\n","Epoch 154/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42085912.0000\n","Epoch 155/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40402228.0000\n","Epoch 156/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45481520.0000\n","Epoch 157/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42739320.0000\n","Epoch 158/300\n","313/313 [==============================] - 0s 1ms/step - loss: 47790604.0000\n","Epoch 159/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38493588.0000\n","Epoch 160/300\n","313/313 [==============================] - 0s 2ms/step - loss: 36462200.0000\n","Epoch 161/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41701816.0000\n","Epoch 162/300\n","313/313 [==============================] - 0s 1ms/step - loss: 36950384.0000\n","Epoch 163/300\n","313/313 [==============================] - 0s 2ms/step - loss: 43164832.0000\n","Epoch 164/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38471556.0000\n","Epoch 165/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38058960.0000\n","Epoch 166/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41515216.0000\n","Epoch 167/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43776440.0000\n","Epoch 168/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42878232.0000\n","Epoch 169/300\n","313/313 [==============================] - 1s 2ms/step - loss: 38989628.0000\n","Epoch 170/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44876712.0000\n","Epoch 171/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42148356.0000\n","Epoch 172/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45462812.0000\n","Epoch 173/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37122016.0000\n","Epoch 174/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40660100.0000\n","Epoch 175/300\n","313/313 [==============================] - 1s 2ms/step - loss: 40855304.0000\n","Epoch 176/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42181568.0000\n","Epoch 177/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40187072.0000\n","Epoch 178/300\n","313/313 [==============================] - 0s 1ms/step - loss: 46459712.0000\n","Epoch 179/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38118160.0000\n","Epoch 180/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38969060.0000\n","Epoch 181/300\n","313/313 [==============================] - 1s 2ms/step - loss: 44960872.0000\n","Epoch 182/300\n","313/313 [==============================] - 1s 2ms/step - loss: 39260984.0000\n","Epoch 183/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39307184.0000\n","Epoch 184/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38409116.0000\n","Epoch 185/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40540084.0000\n","Epoch 186/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41337916.0000\n","Epoch 187/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38494452.0000\n","Epoch 188/300\n","313/313 [==============================] - 0s 2ms/step - loss: 42394872.0000\n","Epoch 189/300\n","313/313 [==============================] - 0s 2ms/step - loss: 41853648.0000\n","Epoch 190/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41620496.0000\n","Epoch 191/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44773052.0000\n","Epoch 192/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41877424.0000\n","Epoch 193/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45922248.0000\n","Epoch 194/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39301844.0000\n","Epoch 195/300\n","313/313 [==============================] - 0s 1ms/step - loss: 35519892.0000\n","Epoch 196/300\n","313/313 [==============================] - 0s 2ms/step - loss: 40277224.0000\n","Epoch 197/300\n","313/313 [==============================] - 1s 2ms/step - loss: 42739472.0000\n","Epoch 198/300\n","313/313 [==============================] - 1s 2ms/step - loss: 43680700.0000\n","Epoch 199/300\n","313/313 [==============================] - 1s 2ms/step - loss: 49038116.0000\n","Epoch 200/300\n","313/313 [==============================] - 1s 2ms/step - loss: 45921092.0000\n","Epoch 201/300\n","313/313 [==============================] - 1s 2ms/step - loss: 42583888.0000\n","Epoch 202/300\n","313/313 [==============================] - 0s 2ms/step - loss: 43420048.0000\n","Epoch 203/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42425824.0000\n","Epoch 204/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44877628.0000\n","Epoch 205/300\n","313/313 [==============================] - 1s 2ms/step - loss: 40320124.0000\n","Epoch 206/300\n","313/313 [==============================] - 1s 2ms/step - loss: 40914772.0000\n","Epoch 207/300\n","313/313 [==============================] - 1s 2ms/step - loss: 42139720.0000\n","Epoch 208/300\n","313/313 [==============================] - 0s 1ms/step - loss: 49830876.0000\n","Epoch 209/300\n","313/313 [==============================] - 0s 1ms/step - loss: 47032292.0000\n","Epoch 210/300\n","313/313 [==============================] - 0s 2ms/step - loss: 42878732.0000\n","Epoch 211/300\n","313/313 [==============================] - 0s 2ms/step - loss: 41703872.0000\n","Epoch 212/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37865372.0000\n","Epoch 213/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44206944.0000\n","Epoch 214/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44345728.0000\n","Epoch 215/300\n","313/313 [==============================] - 0s 2ms/step - loss: 40149504.0000\n","Epoch 216/300\n","313/313 [==============================] - 0s 2ms/step - loss: 37269668.0000\n","Epoch 217/300\n","313/313 [==============================] - 1s 2ms/step - loss: 41724760.0000\n","Epoch 218/300\n","313/313 [==============================] - 0s 2ms/step - loss: 45056952.0000\n","Epoch 219/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44720160.0000\n","Epoch 220/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42182312.0000\n","Epoch 221/300\n","313/313 [==============================] - 0s 878us/step - loss: 37970832.0000\n","Epoch 222/300\n","313/313 [==============================] - 0s 859us/step - loss: 38010688.0000\n","Epoch 223/300\n","313/313 [==============================] - 0s 964us/step - loss: 40328568.0000\n","Epoch 224/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39726648.0000\n","Epoch 225/300\n","313/313 [==============================] - 0s 2ms/step - loss: 40213316.0000\n","Epoch 226/300\n","313/313 [==============================] - 1s 2ms/step - loss: 37452340.0000\n","Epoch 227/300\n","313/313 [==============================] - 1s 2ms/step - loss: 40021776.0000\n","Epoch 228/300\n","313/313 [==============================] - 1s 2ms/step - loss: 44731124.0000\n","Epoch 229/300\n","313/313 [==============================] - 1s 2ms/step - loss: 36823888.0000\n","Epoch 230/300\n","313/313 [==============================] - 1s 2ms/step - loss: 39035704.0000\n","Epoch 231/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39957336.0000\n","Epoch 232/300\n","313/313 [==============================] - 1s 2ms/step - loss: 37276588.0000\n","Epoch 233/300\n","313/313 [==============================] - 1s 2ms/step - loss: 41995952.0000\n","Epoch 234/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40013664.0000\n","Epoch 235/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44305476.0000\n","Epoch 236/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41906536.0000\n","Epoch 237/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39427212.0000\n","Epoch 238/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43310704.0000\n","Epoch 239/300\n","313/313 [==============================] - 1s 2ms/step - loss: 38394108.0000\n","Epoch 240/300\n","313/313 [==============================] - 1s 2ms/step - loss: 43451188.0000\n","Epoch 241/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39268844.0000\n","Epoch 242/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40892676.0000\n","Epoch 243/300\n","313/313 [==============================] - 0s 1ms/step - loss: 50075632.0000\n","Epoch 244/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40506764.0000\n","Epoch 245/300\n","313/313 [==============================] - 0s 1ms/step - loss: 36403100.0000\n","Epoch 246/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38867308.0000\n","Epoch 247/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43262428.0000\n","Epoch 248/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41718576.0000\n","Epoch 249/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42747924.0000\n","Epoch 250/300\n","313/313 [==============================] - 1s 2ms/step - loss: 41918408.0000\n","Epoch 251/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39797716.0000\n","Epoch 252/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38112824.0000\n","Epoch 253/300\n","313/313 [==============================] - 1s 2ms/step - loss: 40772636.0000\n","Epoch 254/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37494796.0000\n","Epoch 255/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42993424.0000\n","Epoch 256/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40613004.0000\n","Epoch 257/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42656716.0000\n","Epoch 258/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43256632.0000\n","Epoch 259/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38277880.0000\n","Epoch 260/300\n","313/313 [==============================] - 1s 2ms/step - loss: 39227260.0000\n","Epoch 261/300\n","313/313 [==============================] - 1s 2ms/step - loss: 40467644.0000\n","Epoch 262/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45157892.0000\n","Epoch 263/300\n","313/313 [==============================] - 0s 2ms/step - loss: 40920112.0000\n","Epoch 264/300\n","313/313 [==============================] - 0s 1ms/step - loss: 38076100.0000\n","Epoch 265/300\n","313/313 [==============================] - 0s 2ms/step - loss: 42974888.0000\n","Epoch 266/300\n","313/313 [==============================] - 1s 2ms/step - loss: 43741312.0000\n","Epoch 267/300\n","313/313 [==============================] - 0s 1ms/step - loss: 50276340.0000\n","Epoch 268/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45100408.0000\n","Epoch 269/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39372808.0000\n","Epoch 270/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44782828.0000\n","Epoch 271/300\n","313/313 [==============================] - 0s 1ms/step - loss: 47423456.0000\n","Epoch 272/300\n","313/313 [==============================] - 0s 1ms/step - loss: 37330772.0000\n","Epoch 273/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40292604.0000\n","Epoch 274/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44077928.0000\n","Epoch 275/300\n","313/313 [==============================] - 0s 1ms/step - loss: 48631044.0000\n","Epoch 276/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43350816.0000\n","Epoch 277/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45340240.0000\n","Epoch 278/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43037396.0000\n","Epoch 279/300\n","313/313 [==============================] - 1s 2ms/step - loss: 47334564.0000\n","Epoch 280/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43183596.0000\n","Epoch 281/300\n","313/313 [==============================] - 0s 2ms/step - loss: 37820316.0000\n","Epoch 282/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41169920.0000\n","Epoch 283/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41608616.0000\n","Epoch 284/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44346308.0000\n","Epoch 285/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43375908.0000\n","Epoch 286/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40319304.0000\n","Epoch 287/300\n","313/313 [==============================] - 0s 1ms/step - loss: 44304008.0000\n","Epoch 288/300\n","313/313 [==============================] - 0s 1ms/step - loss: 39995408.0000\n","Epoch 289/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42753844.0000\n","Epoch 290/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42892848.0000\n","Epoch 291/300\n","313/313 [==============================] - 0s 1ms/step - loss: 41968404.0000\n","Epoch 292/300\n","313/313 [==============================] - 0s 1ms/step - loss: 35171008.0000\n","Epoch 293/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40353228.0000\n","Epoch 294/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43118792.0000\n","Epoch 295/300\n","313/313 [==============================] - 0s 1ms/step - loss: 45058040.0000\n","Epoch 296/300\n","313/313 [==============================] - 0s 2ms/step - loss: 39753416.0000\n","Epoch 297/300\n","313/313 [==============================] - 0s 1ms/step - loss: 40563604.0000\n","Epoch 298/300\n","313/313 [==============================] - 0s 1ms/step - loss: 43551848.0000\n","Epoch 299/300\n","313/313 [==============================] - 0s 1ms/step - loss: 42826688.0000\n","Epoch 300/300\n","313/313 [==============================] - 1s 2ms/step - loss: 38263460.0000\n","Model: \"sequential_10\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_24 (Dense)            (None, 30)                930       \n","                                                                 \n"," batch_normalization_14 (Bat  (None, 30)               120       \n"," chNormalization)                                                \n","                                                                 \n"," dense_25 (Dense)            (None, 1)                 31        \n","                                                                 \n","=================================================================\n","Total params: 1,081\n","Trainable params: 1,021\n","Non-trainable params: 60\n","_________________________________________________________________\n","87/87 [==============================] - 0s 1ms/step\n","[[23881.418 ]\n"," [ 9850.909 ]\n"," [ 6858.035 ]\n"," ...\n"," [13123.187 ]\n"," [ 3049.9614]\n"," [12630.37  ]]\n"]}],"source":["#define model 6 \n","model = keras.models.Sequential([\n","    keras.layers.Dense(30, input_shape=(30,), activation=\"relu\"),\n","    keras.layers.BatchNormalization(),\n","    keras.layers.Dense(1)\n","])\n","\n","model.compile(loss='mean_squared_error', optimizer= tf.keras.optimizers.Adam(0.01))\n","\n","#fit model\n","history = model.fit(X_train, \n","                    y_train, \n","                    epochs= 300)\n","\n","model.summary()\n","\n","#test model\n","print(model.predict(X_test))"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[25005.]\n"," [ 9664.]\n"," [ 6053.]\n"," ...\n"," [12549.]\n"," [ 1204.]\n"," [13000.]]\n"]}],"source":["print(y_test)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('dsenv')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"f9b03efc3cc0cdad902fb01df948dfa308c1bba5d284ef31b186b2f65e4ea318"}}},"nbformat":4,"nbformat_minor":2}
